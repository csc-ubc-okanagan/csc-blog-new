[{"content":"GitHub is a platform that allows you to store, share, and archive files. It is commonly used for in research to make files accessible, including code, data, models, and figures. Sharing code and data through platforms like GitHub helps make research more transparent, reproducible, and credible Braga et al. 2023. In this blog post, I will show you how to create your first GitHub repository (\u0026ldquo;repo\u0026rdquo; for short), how to set up a convenient folder structure, and how to push (i.e., upload) and pull (i.e., download) content to and from the repo. The Center for Scholarly Communication (CSC) also runs a two-part workshop on how to use GitHub. The material is available on the CSC website: Part 1 and Part 2.\nBefore we start, you will need to download and install GitHub Desktop from https://desktop.github.com/download/. While it installs, make an account on github.com if you don\u0026rsquo;t have one already.\nTo make your first repo, go to File/New repository or press Ctrl + N.\nNow choose your repo\u0026rsquo;s name. Something short and simple, like my-first-repo works for now. If you want, you can also add a description of the repo\u0026rsquo;s contents and change the location of the local copy that GitHub Desktop will make. On my personal machine, I tend to save repos in Documents/GitHub, but on my lab machine I save them in my UBC home drive: H:/GitHub. If you are planning on working primarily with only one language (e.g., R or Python), I would suggest choosing the appropriate Git ignore. This will hide files that you generally don\u0026rsquo;t want to push to GitHub (e.g., .Rhistory and .RData files). You can change the .gitignore files later with any text editor. The last step here is to choose a license. If you want a simple open-access licence for code, the MIT one is a good option.\nYou\u0026rsquo;ve now created your first GitHub repo, but it is currently only on your local machine. To push it to GitHub, you\u0026rsquo;ll need to publish the repo (top ribbon, to the right). Before confirming, you can:\nupdate the name (this won\u0026rsquo;t change the name of the folder on your machine), edit the description, decide whether you want the repo to be public or not (it\u0026rsquo;s private by default), and choose if you want to add it into an existing organization (e.g., your lab\u0026rsquo;s organization). Be careful though \u0026ndash; it can be hard to edit the repo after you\u0026rsquo;ve added it to an organization. Now that the repo is on GitHub, you can start pushing and pulling content to and from it. As a general rule, you should always check for any updates by pulling (click Fetch-origin followed by Pull origin) before trying to push anything, otherwise GitHub will have to manage the pull/push conflict by merging the old files (to be pulled) with the new ones (to be pushed). This can be quite confusing, so it\u0026rsquo;s always good to make to pull first (even if you\u0026rsquo;re the only one working on the repo on two machines). Once you have some files you want to push to the repo, select the ones you want to push by clicking on the boxes in the upper left, add a summary for the commit (i.e., the series of changes to push) at the bottom of the column. Commit summaries should be brief and simple but clear, like \u0026ldquo;cleaned data and started model fitting\u0026rdquo;. You can use markdown in both the summary and the description (see the field below the summary field) for messages like \u0026ldquo;removed unnecessary library() calls\u0026rdquo; using \\(\\text{text}\\). In the changes column, green \u0026ldquo;+\u0026rdquo; symbols indicate new files, yellow dots indicate changed files, and red \u0026ldquo;-\u0026rdquo; symbols indicate file deletions. The panel on the right will show you exactly what portions of a file you changed, if the file is a simple text file (e.g., .csv., .R, .Rmd, .md, and .txt, but not .pdf, .doc, .ppt, or .rds). Consequently, GitHub\u0026rsquo;s version control and edit history work best if you use simple text files as much as possible. Once you\u0026rsquo;ve committed all your changes, don\u0026rsquo;t forget to push the changes to GitHub using the \u0026ldquo;Push origin\u0026rdquo; button! You can check the status of your changes by going to GitHub and navigating to your repo.\nReferences Braga P.H.P., Hébert K., Hudgins E.J., Scott E.R., Edwards B.P.M., Sánchez Reyes L.L., et al. (2023). Not just for programmers: How GitHub can accelerate collaborative and reproducible research in ecology and evolution. Methods in Ecology and Evolution 14, 1364–1380. https://doi.org/10.1111/2041-210X.14108\n","date":"2024-09-16T12:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/getting-started-with-github/","title":"Getting started with GitHub"},{"content":"Creating Sample Datasets This guide provides instructions on how to create sample datasets in R and Python. You can use these methods to generate a mini version of your original dataset for data consultations, enabling efficient and effective analysis on a manageable subset of your data. We assume you know how to read in your data, however, if you need step by step instructions on this, these are available further down the page for both R and Python.\nR Prerequisites\nYou will need dplyr installed. You can double check that you have it installed:\n1 find.package(\u0026#34;dplyr\u0026#34;) # returns an error if the package is not installed, else returns the path to the package 1 ## [1] \u0026#34;/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/dplyr\u0026#34; And install it if necessary:\n1 install.packages(\u0026#34;dplyr\u0026#34;) # REQUIRED We want a minimum of 10 samples per variable or a maximum of 40% of your data if there is concern that 10 samples per variable will be insufficient for demonstration purposes. We want to store the output as an R object.\n10 samples per variable\nReplace your_data_frame in the second line with the name you assigned to your data on import. Replace \u0026quot;path/to/your/file.RData\u0026quot; in the last line with the path and file name to save your sampled data to. 1 2 3 4 5 library(dplyr) df_to_sample \u0026lt;- your_data_frame n_samples \u0026lt;- ncol(df_to_sample) * 10 # calculate the number of variables in your data frame and multiply by 10 sampled_data \u0026lt;- df_to_sample %\u0026gt;% slice_sample(n_samples) # take the sample save(sampled_data, file = \u0026#34;path/to/your/file.RData\u0026#34;) # choose a location to save your RData file with the .RData extension Bring the resulting .RData file with you to your consultation.\n40% of your observations\nReplace your_data_frame in the second line with the name you assigned to your data on import. Replace \u0026quot;path/to/your/file.RData\u0026quot; in the last line with the path and file name to save your sampled data to. 1 2 3 4 5 library(dplyr) df_to_sample \u0026lt;- your_data_frame n_samples \u0026lt;- round(nrow(df_to_sample) * 0.4) # calculate the number of observations in your data frame and multiply by 0.4 sampled_data \u0026lt;- df_to_sample %\u0026gt;% slice_sample(n_samples) # take the sample save(sampled_data, file = \u0026#34;path/to/your/file.RData\u0026#34;) # choose a location to save your RData file with the .RData extension Bring the resulting .RData file with you to your consultation.\nPython We want a minimum of 10 samples per variable or a maximum of 40% of your data if there is concern that 10 samples per variable will be insufficient for demonstration purposes. We want to store the output as a csv file.\n10 samples per variable\nReplace your_data_frame in the second line with the name you assigned to your data on import. Replace \u0026quot;path/to/your/file.RData\u0026quot; in the last line with the path and file name to save your sampled data to. 1 2 3 4 5 import pandas as pd df_to_sample = your_data_frame n_samples = len(df_to_sample.columns) * 10 # calculate the number of variables in your data frame and multiply by 10 sampled_data = df_to_sample.sample(n = n_samples) # take the sample sampled_data.to_csv(\u0026#34;path/to/your/file.csv\u0026#34;) # choose a location to save your csv file with a .csv extension Bring the resulting .csv filw with you to your consultation.\n40% of your observations\nReplace your_data_frame in the second line with the name you assigned to your data on import. Replace \u0026quot;path/to/your/file.RData\u0026quot; in the last line with the path and file name to save your sampled data to. 1 2 3 4 5 import pandas as pd df_to_sample = your_data_frame n_samples = round(df_to_sample.shape[0] * 0.4) # calculate the number of observations in your data frame and multiply by 0.4 sampled_data = df_to_sample.sample(n = n_samples) # take the sample sampled_data.to_csv(\u0026#34;path/to/your/file.csv\u0026#34;) # choose a location to save your csv file with a .csv extension Importing data Importing Data into R Prerequisites\nMake sure you have the readr package for CSV, readxl package for Excel, or jsonlite package for JSON installed. If not, you can install them using:\n1 2 3 install.packages(\u0026#34;readr\u0026#34;) # if reading in csv or other delimited rectangular data install.packages(\u0026#34;readxl\u0026#34;) # if reading in Excel files install.packages(\u0026#34;jsonlite\u0026#34;) # if reading in JSON files Import CSV file: 1 2 library(readr) df_to_sample \u0026lt;- read_csv(\u0026#39;path/to/your/file.csv\u0026#39;) Import Excel file: 1 2 library(readxl) df_to_sample \u0026lt;- read_excel(\u0026#39;path/to/your/file.xlsx\u0026#39;) Import JSON file 1 2 library(jsonlite) df_to_sample \u0026lt;- fromJSON(\u0026#39;path/to/your/file.json\u0026#39;) Importing Data in Python Import CSV file: 1 2 import pandas as pd df_to_sample = pd.read_csv(\u0026#39;path/to/your/file.csv\u0026#39;) Import Excel file: 1 2 import pandas as pd df_to_sample = pd.read_excel(\u0026#39;path/to/your/file.xlsx\u0026#39;) Import JSON file: 1 2 import pandas as pd df_to_sample = pd.read_json(\u0026#39;path/to/your/file.json\u0026#39;) ","date":"2024-04-09T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/sample-data-generation/","title":"Sample Data Generation"},{"content":"In previous categories we have looked at cleaning, summarizing, and subsetting data, with some minor calculations, but we haven’t yet looked at analyzing our data.\nR is a very powerful tool for data analysis. We can fit linear models and view graphs. First, we will look at some basic data analysis processes in R.\nLet’s re-load in our Gapminder data:\n1 2 3 link \u0026lt;- \u0026#39;https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv\u0026#39; df \u0026lt;- read.csv(url(link)) head(df) 1 2 3 4 5 6 7 ## country continent year lifeExp pop gdpPercap ## 1 Afghanistan Asia 1952 28.801 8425333 779.4453 ## 2 Afghanistan Asia 1957 30.332 9240934 820.8530 ## 3 Afghanistan Asia 1962 31.997 10267083 853.1007 ## 4 Afghanistan Asia 1967 34.020 11537966 836.1971 ## 5 Afghanistan Asia 1972 36.088 13079460 739.9811 ## 6 Afghanistan Asia 1977 38.438 14880372 786.1134 Linear Modelling Let’s say we want to fit a linear model to see if there is a relationship between population and time. First, let’s do this with the entire dataset with all countries.\nWe know that there is Simple Linear Regression (SLR) and Multiple Linear Regression (MLR). See the pseudocode below for a layout on how to form both in R.\n1 2 3 4 5 6 # Simple Linear Regression # model_name \u0026lt;- lm(Y ~ X, data = dataframe) # Multiple Linear Regression # model_name \u0026lt;- lm(Y ~ X1 + X2 + ..., data = dataframe) # model_name \u0026lt;- lm(Y ~ ., data = dataframe) to use all variables except Y Now that we have the layout of the code down, let\u0026rsquo;s use Y as population and X as year for an SLR model.\n1 2 model1 \u0026lt;- lm(pop ~ year, data = df) summary(model1) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## ## Call: ## lm(formula = pop ~ year, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -43318856 -27548179 -18558743 -9628265 1275164661 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -972185807 294031308 -3.306 0.000965 *** ## year 506081 148532 3.407 0.000672 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 105800000 on 1702 degrees of freedom ## Multiple R-squared: 0.006775,\tAdjusted R-squared: 0.006191 ## F-statistic: 11.61 on 1 and 1702 DF, p-value: 0.0006716 Now, let\u0026rsquo;s perform MLR with two variables, year and lifeExp.\n1 2 model2 \u0026lt;- lm(pop ~ year + lifeExp, data = df) summary(model2) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ## ## Call: ## lm(formula = pop ~ year + lifeExp, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -47148304 -27382074 -18454446 -8444157 1273829226 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -799315581 321078589 -2.489 0.0129 * ## year 409882 164973 2.485 0.0131 * ## lifeExp 295176 220507 1.339 0.1809 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 105800000 on 1701 degrees of freedom ## Multiple R-squared: 0.00782,\tAdjusted R-squared: 0.006653 ## F-statistic: 6.703 on 2 and 1701 DF, p-value: 0.00126 Finally, let\u0026rsquo;s perform MLR with all variables in the dataset.\n1 2 model3 \u0026lt;- lm(pop ~ ., data = df) summary(model3) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 ## ## Call: ## lm(formula = pop ~ ., data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -375691051 -5548380 -604356 4854327 391492520 ## ## Coefficients: (4 not defined because of singularities) ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -2.211e+08 1.677e+08 -1.319 0.187435 ## countryAlbania -5.423e+07 1.431e+07 -3.789 0.000157 *** ## countryAlgeria -2.412e+07 1.347e+07 -1.790 0.073575 . ## countryAngola -8.521e+06 1.259e+07 -0.677 0.498532 ## countryArgentina -2.796e+07 1.449e+07 -1.930 0.053788 . ## countryAustralia -4.731e+07 1.550e+07 -3.053 0.002304 ** ## countryAustria -5.220e+07 1.533e+07 -3.405 0.000678 *** ## countryBahrain -4.982e+07 1.443e+07 -3.453 0.000568 *** ## countryBangladesh 5.839e+07 1.287e+07 4.538 6.10e-06 *** ## countryBelgium -5.088e+07 1.537e+07 -3.310 0.000954 *** ## countryBenin -2.687e+07 1.282e+07 -2.096 0.036235 * ## countryBolivia -2.992e+07 1.302e+07 -2.299 0.021637 * ## countryBosnia and Herzegovina -5.198e+07 1.424e+07 -3.650 0.000271 *** ## countryBotswana -3.697e+07 1.316e+07 -2.808 0.005043 ** ## countryBrazil 7.429e+07 1.376e+07 5.400 7.68e-08 *** ## countryBulgaria -4.978e+07 1.450e+07 -3.432 0.000614 *** ## countryBurkina Faso -1.793e+07 1.268e+07 -1.414 0.157468 ## countryBurundi -2.106e+07 1.268e+07 -1.661 0.096887 . ## countryCambodia -2.130e+07 1.278e+07 -1.666 0.095911 . ## countryCameroon -2.008e+07 1.280e+07 -1.569 0.116755 ## countryCanada -3.735e+07 1.563e+07 -2.389 0.017010 * ## countryCentral African Republic -2.179e+07 1.266e+07 -1.722 0.085353 . ## countryChad -2.287e+07 1.274e+07 -1.795 0.072860 . ## countryChile -4.360e+07 1.427e+07 -3.056 0.002279 ** ## countryChina 9.099e+08 1.366e+07 66.602 \u0026lt; 2e-16 *** ## countryColombia -2.330e+07 1.388e+07 -1.679 0.093446 . ## countryComoros -3.532e+07 1.300e+07 -2.718 0.006646 ** ## countryCongo, Dem. Rep. 7.368e+06 1.267e+07 0.581 0.561055 ## countryCongo, Rep. -3.354e+07 1.302e+07 -2.576 0.010080 * ## countryCosta Rica -5.633e+07 1.453e+07 -3.876 0.000111 *** ## countryCote d\u0026#39;Ivoire -2.113e+07 1.281e+07 -1.650 0.099208 . ## countryCroatia -5.353e+07 1.460e+07 -3.666 0.000255 *** ## countryCuba -5.049e+07 1.464e+07 -3.448 0.000580 *** ## countryCzech Republic -4.891e+07 1.490e+07 -3.283 0.001050 ** ## countryDenmark -5.625e+07 1.554e+07 -3.620 0.000304 *** ## countryDjibouti -2.712e+07 1.274e+07 -2.129 0.033376 * ## countryDominican Republic -4.194e+07 1.366e+07 -3.071 0.002169 ** ## countryEcuador -4.060e+07 1.381e+07 -2.941 0.003322 ** ## countryEgypt 6.005e+06 1.325e+07 0.453 0.650446 ## countryEl Salvador -4.046e+07 1.352e+07 -2.993 0.002807 ** ## countryEquatorial Guinea -2.252e+07 1.264e+07 -1.781 0.075048 . ## countryEritrea -2.446e+07 1.271e+07 -1.924 0.054538 . ## countryEthiopia 1.638e+07 1.267e+07 1.293 0.196194 ## countryFinland -5.543e+07 1.520e+07 -3.648 0.000273 *** ## countryFrance -8.804e+06 1.541e+07 -0.571 0.567874 ## countryGabon -3.138e+07 1.310e+07 -2.396 0.016694 * ## countryGambia -2.432e+07 1.267e+07 -1.920 0.055049 . ## countryGermany 1.733e+07 1.538e+07 1.127 0.259883 ## countryGhana -2.306e+07 1.299e+07 -1.775 0.076090 . ## countryGreece -5.244e+07 1.515e+07 -3.460 0.000555 *** ## countryGuatemala -3.413e+07 1.329e+07 -2.567 0.010339 * ## countryGuinea -1.818e+07 1.264e+07 -1.438 0.150520 ## countryGuinea-Bissau -1.729e+07 1.258e+07 -1.374 0.169663 ## countryHaiti -2.725e+07 1.288e+07 -2.115 0.034566 * ## countryHonduras -3.889e+07 1.337e+07 -2.909 0.003672 ** ## countryHong Kong, China -5.631e+07 1.521e+07 -3.703 0.000220 *** ## countryHungary -4.642e+07 1.457e+07 -3.186 0.001473 ** ## countryIceland -6.410e+07 1.575e+07 -4.071 4.91e-05 *** ## countryIndia 6.643e+08 1.304e+07 50.949 \u0026lt; 2e-16 *** ## countryIndonesia 1.101e+08 1.311e+07 8.396 \u0026lt; 2e-16 *** ## countryIran -6.002e+05 1.349e+07 -0.045 0.964511 ## countryIraq -2.588e+07 1.334e+07 -1.939 0.052645 . ## countryIreland -5.722e+07 1.513e+07 -3.781 0.000162 *** ## countryIsrael -5.786e+07 1.515e+07 -3.819 0.000139 *** ## countryItaly -7.265e+06 1.527e+07 -0.476 0.634287 ## countryJamaica -5.453e+07 1.439e+07 -3.789 0.000157 *** ## countryJapan 4.916e+07 1.542e+07 3.187 0.001465 ** ## countryJordan -4.258e+07 1.351e+07 -3.151 0.001656 ** ## countryKenya -1.790e+07 1.301e+07 -1.376 0.169170 ## countryKorea, Dem. Rep. -3.402e+07 1.383e+07 -2.459 0.014037 * ## countryKorea, Rep. -1.476e+07 1.406e+07 -1.050 0.293722 ## countryKuwait -4.441e+07 1.832e+07 -2.424 0.015450 * ## countryLebanon -4.982e+07 1.412e+07 -3.528 0.000431 *** ## countryLesotho -3.122e+07 1.287e+07 -2.425 0.015431 * ## countryLiberia -2.074e+07 1.263e+07 -1.643 0.100642 ## countryLibya -3.974e+07 1.365e+07 -2.911 0.003652 ** ## countryMadagascar -1.960e+07 1.278e+07 -1.534 0.125294 ## countryMalawi -1.672e+07 1.264e+07 -1.322 0.186342 ## countryMalaysia -3.626e+07 1.393e+07 -2.602 0.009349 ** ## countryMali -1.668e+07 1.264e+07 -1.319 0.187231 ## countryMauritania -3.379e+07 1.299e+07 -2.600 0.009400 ** ## countryMauritius -5.093e+07 1.399e+07 -3.641 0.000280 *** ## countryMexico 1.651e+07 1.409e+07 1.172 0.241337 ## countryMongolia -3.857e+07 1.321e+07 -2.919 0.003558 ** ## countryMontenegro -5.799e+07 1.458e+07 -3.977 7.29e-05 *** ## countryMorocco -2.191e+07 1.334e+07 -1.642 0.100692 ## countryMozambique -7.711e+06 1.259e+07 -0.612 0.540438 ## countryMyanmar -3.676e+06 1.305e+07 -0.282 0.778138 ## countryNamibia -3.556e+07 1.308e+07 -2.719 0.006626 ** ## countryNepal -1.469e+07 1.283e+07 -1.145 0.252448 ## countryNetherlands -4.915e+07 1.569e+07 -3.132 0.001769 ** ## countryNew Zealand -5.847e+07 1.530e+07 -3.821 0.000138 *** ## countryNicaragua -4.023e+07 1.340e+07 -3.001 0.002732 ** ## countryNiger -1.845e+07 1.267e+07 -1.456 0.145611 ## countryNigeria 4.984e+07 1.265e+07 3.940 8.51e-05 *** ## countryNorway -5.822e+07 1.597e+07 -3.646 0.000275 *** ## countryOman -4.030e+07 1.359e+07 -2.965 0.003069 ** ## countryPakistan 5.468e+07 1.315e+07 4.159 3.37e-05 *** ## countryPanama -5.350e+07 1.429e+07 -3.745 0.000187 *** ## countryParaguay -5.108e+07 1.415e+07 -3.611 0.000315 *** ## countryPeru -2.598e+07 1.347e+07 -1.928 0.054039 . ## countryPhilippines 5.621e+06 1.360e+07 0.413 0.679421 ## countryPoland -2.383e+07 1.459e+07 -1.633 0.102628 ## countryPortugal -4.834e+07 1.470e+07 -3.289 0.001028 ** ## countryPuerto Rico -5.801e+07 1.494e+07 -3.882 0.000108 *** ## countryReunion -5.358e+07 1.415e+07 -3.785 0.000159 *** ## countryRomania -3.503e+07 1.437e+07 -2.438 0.014885 * ## countryRwanda -1.591e+07 1.261e+07 -1.262 0.207196 ## countrySao Tome and Principe -4.295e+07 1.335e+07 -3.217 0.001324 ** ## countrySaudi Arabia -2.802e+07 1.391e+07 -2.015 0.044058 * ## countrySenegal -2.684e+07 1.291e+07 -2.080 0.037702 * ## countrySerbia -4.703e+07 1.444e+07 -3.257 0.001151 ** ## countrySierra Leone -1.122e+07 1.258e+07 -0.892 0.372703 ## countrySingapore -5.517e+07 1.499e+07 -3.680 0.000241 *** ## countrySlovak Republic -5.370e+07 1.470e+07 -3.653 0.000268 *** ## countrySlovenia -5.719e+07 1.491e+07 -3.835 0.000130 *** ## countrySomalia -1.526e+07 1.260e+07 -1.211 0.226045 ## countrySouth Africa -6.780e+06 1.316e+07 -0.515 0.606543 ## countrySpain -2.663e+07 1.521e+07 -1.750 0.080268 . ## countrySri Lanka -3.997e+07 1.410e+07 -2.834 0.004649 ** ## countrySudan -8.692e+06 1.281e+07 -0.679 0.497470 ## countrySwaziland -3.013e+07 1.284e+07 -2.346 0.019114 * ## countrySweden -5.577e+07 1.568e+07 -3.557 0.000386 *** ## countrySwitzerland -5.543e+07 1.595e+07 -3.475 0.000525 *** ## countrySyria -3.750e+07 1.364e+07 -2.749 0.006043 ** ## countryTaiwan -4.115e+07 1.466e+07 -2.808 0.005049 ** ## countryTanzania -9.287e+06 1.278e+07 -0.726 0.467660 ## countryThailand -3.539e+06 1.371e+07 -0.258 0.796393 ## countryTogo -3.164e+07 1.295e+07 -2.443 0.014670 * ## countryTrinidad and Tobago -5.277e+07 1.423e+07 -3.709 0.000216 *** ## countryTunisia -3.975e+07 1.359e+07 -2.924 0.003502 ** ## countryTurkey 1.033e+06 1.352e+07 0.076 0.939115 ## countryUganda -1.504e+07 1.277e+07 -1.178 0.239162 ## countryUnited Kingdom -4.993e+06 1.538e+07 -0.325 0.745519 ## countryUnited States 1.690e+08 1.566e+07 10.794 \u0026lt; 2e-16 *** ## countryUruguay -5.631e+07 1.463e+07 -3.848 0.000124 *** ## countryVenezuela -3.789e+07 1.426e+07 -2.658 0.007945 ** ## countryVietnam 1.200e+07 1.332e+07 0.901 0.367650 ## countryWest Bank and Gaza -4.401e+07 1.356e+07 -3.245 0.001201 ** ## countryYemen, Rep. -1.729e+07 1.274e+07 -1.357 0.175082 ## countryZambia -2.077e+07 1.272e+07 -1.633 0.102627 ## countryZimbabwe -2.855e+07 1.301e+07 -2.194 0.028351 * ## continentAmericas NA NA NA NA ## continentAsia NA NA NA NA ## continentEurope NA NA NA NA ## continentOceania NA NA NA NA ## year 9.442e+04 8.804e+04 1.072 0.283681 ## lifeExp 1.339e+06 2.189e+05 6.118 1.19e-09 *** ## gdpPercap -1.908e+02 1.655e+02 -1.153 0.248975 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 30810000 on 1559 degrees of freedom ## Multiple R-squared: 0.9229,\tAdjusted R-squared: 0.9158 ## F-statistic: 129.6 on 144 and 1559 DF, p-value: \u0026lt; 2.2e-16 Note that the outputs give us a lot of information. We see the default hypotheses tested, with p-values for each coefficient and for the model as a whole. We see the RSE and the degrees of freedom, F-test, R-squared values, and much more! There are a lot of insights that we can extract from this simple output.\n","date":"2023-08-01T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/basic-model-fitting-in-r/","title":"Basic Model Fitting in R"},{"content":"Occasionally we need to derive variables form existing information. A good example of this is conversion between scales. If we wanted to change a measurement from metres to kilometres or weight in pounds to kilograms, we could do this simply by performing a basic operation on an entire column. In this situation, let’s start by multiplying two columns together to create a new column. Recall the GDP dataset from previous articles. Let’s say we want to know the total GDP for the country. This could be calculated by multiplying the population by the GDP_per_Cap.\nIf you are just starting here, let’s re-load in the Gapminder data that we have been using in previous posts:\n1 2 link \u0026lt;- \u0026#39;https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv\u0026#39; df \u0026lt;- read.csv(url(link)) 1 2 df$Total_GDP \u0026lt;- df$pop * df$gdpPercap head(df) 1 2 3 4 5 6 7 ## country continent year lifeExp pop gdpPercap Total_GDP ## 1 Afghanistan Asia 1952 28.801 8425333 779.4453 6567086330 ## 2 Afghanistan Asia 1957 30.332 9240934 820.8530 7585448670 ## 3 Afghanistan Asia 1962 31.997 10267083 853.1007 8758855797 ## 4 Afghanistan Asia 1967 34.020 11537966 836.1971 9648014150 ## 5 Afghanistan Asia 1972 36.088 13079460 739.9811 9678553274 ## 6 Afghanistan Asia 1977 38.438 14880372 786.1134 11697659231 Since the number is too large to actually interpret, let’s divide it by 1 billion so that the unit of measure is in billions. We will also rename the column to represent this change.\n1 2 3 4 df$Total_GDP \u0026lt;- df$Total_GDP / 1000000000 # names(df)[names(df) == \u0026#39;old.var.name\u0026#39;] \u0026lt;- \u0026#39;new.var.name\u0026#39; names(df)[names(df) == \u0026#39;Total_GDP\u0026#39;] \u0026lt;- \u0026#39;TotalGDP_Bil\u0026#39; head(df) 1 2 3 4 5 6 7 ## country continent year lifeExp pop gdpPercap TotalGDP_Bil ## 1 Afghanistan Asia 1952 28.801 8425333 779.4453 6.567086 ## 2 Afghanistan Asia 1957 30.332 9240934 820.8530 7.585449 ## 3 Afghanistan Asia 1962 31.997 10267083 853.1007 8.758856 ## 4 Afghanistan Asia 1967 34.020 11537966 836.1971 9.648014 ## 5 Afghanistan Asia 1972 36.088 13079460 739.9811 9.678553 ## 6 Afghanistan Asia 1977 38.438 14880372 786.1134 11.697659 Note that if you were to run this multiple times, it would keep dividing by 1 billion each time, so we want to ensure it is only run once.\nNow, let’s say we want to create a new column that contains both the country and continent information together. This is a useful tool if you had information where a first name and last name were separated, or even there was a username and you wanted to create a new column by combining the username and an email extension. Let’s take a look at our example.\n1 2 df$Country_Cont \u0026lt;- paste(df$country, \u0026#39;_\u0026#39;, df$continent) head(df) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## country continent year lifeExp pop gdpPercap TotalGDP_Bil ## 1 Afghanistan Asia 1952 28.801 8425333 779.4453 6.567086 ## 2 Afghanistan Asia 1957 30.332 9240934 820.8530 7.585449 ## 3 Afghanistan Asia 1962 31.997 10267083 853.1007 8.758856 ## 4 Afghanistan Asia 1967 34.020 11537966 836.1971 9.648014 ## 5 Afghanistan Asia 1972 36.088 13079460 739.9811 9.678553 ## 6 Afghanistan Asia 1977 38.438 14880372 786.1134 11.697659 ## Country_Cont ## 1 Afghanistan _ Asia ## 2 Afghanistan _ Asia ## 3 Afghanistan _ Asia ## 4 Afghanistan _ Asia ## 5 Afghanistan _ Asia ## 6 Afghanistan _ Asia There are so many different ways to perform an operation like this.\nAs an exercise, try creating your own column using either a basic mathematical operation on an existing column, or by combining two columns, or anything else you can think of!\nSome examples:\nCreate a new column with the first three letters of the country name Create a column to show TRUE if the TotalGDP_Bil is greater than 5, FALSE if not. Combine the country name with the year. Here are the solutions to the examples provided above.\n1 2 3 # Solution to #1 df$first_3_letters \u0026lt;- substr(df$country, 1, 3) head(df) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## country continent year lifeExp pop gdpPercap TotalGDP_Bil ## 1 Afghanistan Asia 1952 28.801 8425333 779.4453 6.567086 ## 2 Afghanistan Asia 1957 30.332 9240934 820.8530 7.585449 ## 3 Afghanistan Asia 1962 31.997 10267083 853.1007 8.758856 ## 4 Afghanistan Asia 1967 34.020 11537966 836.1971 9.648014 ## 5 Afghanistan Asia 1972 36.088 13079460 739.9811 9.678553 ## 6 Afghanistan Asia 1977 38.438 14880372 786.1134 11.697659 ## Country_Cont first_3_letters ## 1 Afghanistan _ Asia Afg ## 2 Afghanistan _ Asia Afg ## 3 Afghanistan _ Asia Afg ## 4 Afghanistan _ Asia Afg ## 5 Afghanistan _ Asia Afg ## 6 Afghanistan _ Asia Afg 1 2 3 # Solution to #2 df$GDP_Bool \u0026lt;- ifelse(df$TotalGDP_Bil \u0026gt; 5, \u0026#34;TRUE\u0026#34;, \u0026#34;FALSE\u0026#34;) head(df) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## country continent year lifeExp pop gdpPercap TotalGDP_Bil ## 1 Afghanistan Asia 1952 28.801 8425333 779.4453 6.567086 ## 2 Afghanistan Asia 1957 30.332 9240934 820.8530 7.585449 ## 3 Afghanistan Asia 1962 31.997 10267083 853.1007 8.758856 ## 4 Afghanistan Asia 1967 34.020 11537966 836.1971 9.648014 ## 5 Afghanistan Asia 1972 36.088 13079460 739.9811 9.678553 ## 6 Afghanistan Asia 1977 38.438 14880372 786.1134 11.697659 ## Country_Cont first_3_letters GDP_Bool ## 1 Afghanistan _ Asia Afg TRUE ## 2 Afghanistan _ Asia Afg TRUE ## 3 Afghanistan _ Asia Afg TRUE ## 4 Afghanistan _ Asia Afg TRUE ## 5 Afghanistan _ Asia Afg TRUE ## 6 Afghanistan _ Asia Afg TRUE 1 2 3 # Solution to #3 df$Country_Year \u0026lt;- paste(df$country, \u0026#39;_\u0026#39;, df$year) head(df) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## country continent year lifeExp pop gdpPercap TotalGDP_Bil ## 1 Afghanistan Asia 1952 28.801 8425333 779.4453 6.567086 ## 2 Afghanistan Asia 1957 30.332 9240934 820.8530 7.585449 ## 3 Afghanistan Asia 1962 31.997 10267083 853.1007 8.758856 ## 4 Afghanistan Asia 1967 34.020 11537966 836.1971 9.648014 ## 5 Afghanistan Asia 1972 36.088 13079460 739.9811 9.678553 ## 6 Afghanistan Asia 1977 38.438 14880372 786.1134 11.697659 ## Country_Cont first_3_letters GDP_Bool Country_Year ## 1 Afghanistan _ Asia Afg TRUE Afghanistan _ 1952 ## 2 Afghanistan _ Asia Afg TRUE Afghanistan _ 1957 ## 3 Afghanistan _ Asia Afg TRUE Afghanistan _ 1962 ## 4 Afghanistan _ Asia Afg TRUE Afghanistan _ 1967 ## 5 Afghanistan _ Asia Afg TRUE Afghanistan _ 1972 ## 6 Afghanistan _ Asia Afg TRUE Afghanistan _ 1977 ","date":"2023-08-01T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/creating-variables-in-r/","title":"Creating Variables in R"},{"content":"Python and R are both very useful tools in academia, research, industry, and everywhere! They have a lot of similarities, but there are also many differences.\nThe purpose of this post is to help students to decide which language to learn first, according to their differences, similarities, and departmental practices.\nFirst, let\u0026rsquo;s introduce each, and talk about their main purposes.\nIntroducing Python Python is a general-purpose, object-oriented programming language. It was created in 1991, and it has a community of people who contribute to regularly updating libraries and improving efficiencies. It happens to be one of the most popular programming languages in the world. Some of the most common libraries for data-related tasks include NumPy (for arrays), Pandas (for data analysis and manipulation), and MatPlotLib (for data visualizations). Python is a powerful tool used for machine learning, deep learning, and modelling. Jupyter Notebook is a useful interface to pair with Python because it allows for clean, readable layouts to be shared with peers and users. Note that Jupyter Notebook also supports R.\nPython is commonly used in disciplines such as computer science, data science, mathematics (optimization, pure math, finance, economics, etc.), physics, engineering, the social sciences, and more. Note that this is just a general consensus. Your specific department at UBC, or your previous institution, may have done something differently.\nIntroducing R R was originally created for statistics, specializing in statistical analysis and visualization. R was created in 1993, but generally has less community support and less advancements than Python. This is one of the major complaints of users, and is one reason why many people end up turning to Python over R. Libraries and tools in R are best known for helping with tasks such as cleaning data, creating visualization, and training some machine learning and deep learning algorithms. Note that R can take significantly longer to handle machine learning algorithms than alternatives such as Python.\nR is commonly used in disciplines such as biology and math (statistics). Again, this is just a general consensus, and your specific department may use a different tool.\nSimilarities Both R and Python are open source programming languages that are maintained and supported by large communities.\nDifferences Here, we will discuss some of the differences between R and Python, which can help to decide which to start learning first.\nR is mainly used for statistical analysis, but Python is traditionally better for data wrangling. Python is more multi-purpose, and these skills can be transferable to other things, such as web development or application development. Python has a readable syntax that is easier to learn.\nLet\u0026rsquo;s take a look at this chart below to look at more differences between the two.\nR Python mainly used for statistical analysis | - better for data wrangling leans towards statistical modelling and analytics | - more multi-purpose (can transfer skills to application or web development) can perform deep statistical analysis in short code chunks | - more readable syntax data visualizations can be built from models with ggplot2 | - scalable for machine learning and data analysis, Altair has interactive and customizable visualizations only supports data formats from Excel, CSV, txt files | - supports many data formats (CSV, JSON, SQL tables, web requested data, etc.) optimized for statistical analysis of large datasets | - Pandas let\u0026rsquo;s you filter and sort data almost instantly modelling analysis requires non-core R (tidyverse used for importing, visualizing, reporting, etc.) | - standard libraries used work together well (NumPy, SciPy, scikit-learn) General Preferences In general, it is commonly considered that if you have programming experience, Python is the way to go, because it is a very easy language to learn (compared to others). If you are new to programming, Python is also considered a great learning language for beginners, and R may take some extra efforts to develop expertise.\nIf your team or supervisor prefers one language over another, it is usually easier to stick with what the people around you are using. This will allow them to help you if you run into issues. Talk to your team to find out what the majority of them prefer to use.\nOverall, R is better for statistical learning, and Python is better for machine learning, large-scaled apps, and data analysis within the web and its applications. Python and R both have great visualization tools, and you can read posts about those here as well, so visualizations shouldn\u0026rsquo;t prevent you from deciding between the two.\nR and Python are both wonderful tools to have in your toolbox for all academic and professional endeavours. When in doubt, just learn both! But if you don\u0026rsquo;t have the time, hopefully this information helps to make a more informed decision. It is also easier to learn one if you already have familiarity with the other, so feel free to keep the door open to return to learning the other option down the road.\n","date":"2023-07-26T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/python-vs-r-how-to-decide/","title":"Python vs R - How To Decide?"},{"content":"As we know, Jupyter Notebook can be used easily with our UBC login information via Syzygy. Jupyter Notebook can also be downloaded to a computer and used via Anaconda. There are many different interfaces that allow us to use Python. One of the more interesting ones to note is actually RStudio. There is a package in R called reticulate that allows us to create an RMarkdown file and use both R and Python code chunks within the same file. This is actually how this blog is able to show both R and Python content! Let\u0026rsquo;s get started on how reticulate is used in RStudio to include Python code.\nInstallation First, installation is required. To install the reticulate package in RStudio from CRAN, type the following:\n1 install.packages(\u0026#34;reticulate\u0026#34;) Python Version Next, we need to access the version of Python desired. Reticulate will, by default, find and use the version of Python via PATH. To check this, type Sys.which(\u0026quot;python\u0026quot;).\nIf you would like to change the version to something other than what is found in PATH, try the use_python() function. Here is an example of how to call the package from the library, and then use a different path to get to the desired Python version.\n1 2 library(reticulate) use_python(\u0026#34;/my/file/path/python\u0026#34;) Getting Started Now that the reticulate package has been installed, we can start using Python within an RMarkdown document.\nOnce an RMarkdown file has been started, create a new code block. Note that on a Windows, a shortcut for adding a new code block is Ctrl+alt+i. Once a new code block appears, it should look like this:\nIf you were to type code here, it would be in R. To change it to Python, simply replace the \u0026lsquo;r\u0026rsquo; with \u0026lsquo;python\u0026rsquo;. Then it will look like this:\nNow, the console below will change to show Python code once something in this block is run. You can easily switch back and forth between R and Python from code chunk to code chunk.\nYou can also see your saved variables in the environment, separated between R and Python. Note that when you do something such as import a dataset, if you wanted to perform manipulations on the dataset in both R and Python, you will have to load the dataset in using both R and Python, and it will create separate variables which do not override each other. They will stay speparate in the environment.\nTo change between R and Python environments, go to the Environment window and click the dropdown arrow. It should look like this:\nIf you would like to see some examples, take a look at the _src folder in the GitHub repo for this blog to see how each of the posts are created in both R and Python. The link to the backend content for this blog can be found here.\n","date":"2023-07-26T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/using-python-in-rstudio-with-reticulate-package/","title":"Using Python in RStudio with Reticulate Package"},{"content":"Sometimes the data frame we are working with can be very large and take a while to process. Alternatively, we could only need a portion of the information. There is a way to filter through a data frame such that only the specified information is used, which saves space and time!\nLet’s re-load in our Gapminder data:\n1 2 3 import pandas as pd url = \u0026#39;https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv\u0026#39; df = pd.read_csv(url) We know that we can select just one column like this below:\n1 df[\u0026#39;country\u0026#39;] 1 2 3 4 5 6 7 8 9 10 11 12 ## 0 Afghanistan ## 1 Afghanistan ## 2 Afghanistan ## 3 Afghanistan ## 4 Afghanistan ## ... ## 1699 Zimbabwe ## 1700 Zimbabwe ## 1701 Zimbabwe ## 1702 Zimbabwe ## 1703 Zimbabwe ## Name: country, Length: 1704, dtype: object So if we wanted to create a new data frame by filtering our existing data frame for entries where the country column has the value ‘Canada’, we can do so like this:\n1 2 df_2 = df[df[\u0026#39;country\u0026#39;] == \u0026#39;Canada\u0026#39;] df_2.head() 1 2 3 4 5 6 ## country continent year lifeExp pop gdpPercap ## 240 Canada Americas 1952 68.75 14785584 11367.16112 ## 241 Canada Americas 1957 69.96 17010154 12489.95006 ## 242 Canada Americas 1962 71.30 18985849 13462.48555 ## 243 Canada Americas 1967 72.13 20819767 16076.58803 ## 244 Canada Americas 1972 72.88 22284500 18970.57086 Alternatively, if we didn’t want to create a new data frame, but we wanted to view just a subset of the data frame temporarily, we could write this:\n1 2 cols = [\u0026#39;country\u0026#39;, \u0026#39;continent\u0026#39;, \u0026#39;pop\u0026#39;] df[cols] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## country continent pop ## 0 Afghanistan Asia 8425333 ## 1 Afghanistan Asia 9240934 ## 2 Afghanistan Asia 10267083 ## 3 Afghanistan Asia 11537966 ## 4 Afghanistan Asia 13079460 ## ... ... ... ... ## 1699 Zimbabwe Africa 9216418 ## 1700 Zimbabwe Africa 10704340 ## 1701 Zimbabwe Africa 11404948 ## 1702 Zimbabwe Africa 11926563 ## 1703 Zimbabwe Africa 12311143 ## ## [1704 rows x 3 columns] We could also perform operations such as .mean(), .median(), .max(), etc. using filtering. An example of this can be found below.\n1 2 cols = [\u0026#39;lifeExp\u0026#39;, \u0026#39;pop\u0026#39;, \u0026#39;gdpPercap\u0026#39;] df[cols].mean() 1 2 3 4 ## lifeExp 5.947444e+01 ## pop 2.960121e+07 ## gdpPercap 7.215327e+03 ## dtype: float64 We can select different row \u0026amp; column combinations as well by indexing. If we wanted to select just the first entry in the first row and column, remembering that Python starts indexing at 0, it would look like this:\n1 df.iloc[0,0] 1 ## \u0026#39;Afghanistan\u0026#39; .iloc() is a function that helps us select a particular cell in the data set. We can also use it to select the first row entirely.\n1 df.iloc[0] 1 2 3 4 5 6 7 ## country Afghanistan ## continent Asia ## year 1952 ## lifeExp 28.801 ## pop 8425333 ## gdpPercap 779.445314 ## Name: 0, dtype: object We could also use it to select the first 3 rows like this:\n1 df.iloc[:3] 1 2 3 4 ## country continent year lifeExp pop gdpPercap ## 0 Afghanistan Asia 1952 28.801 8425333 779.445314 ## 1 Afghanistan Asia 1957 30.332 9240934 820.853030 ## 2 Afghanistan Asia 1962 31.997 10267083 853.100710 Which is equivalent to:\n1 df.iloc[0:3] 1 2 3 4 ## country continent year lifeExp pop gdpPercap ## 0 Afghanistan Asia 1952 28.801 8425333 779.445314 ## 1 Afghanistan Asia 1957 30.332 9240934 820.853030 ## 2 Afghanistan Asia 1962 31.997 10267083 853.100710 If we wanted to select the first column only:\n1 df.iloc[:,0] 1 2 3 4 5 6 7 8 9 10 11 12 ## 0 Afghanistan ## 1 Afghanistan ## 2 Afghanistan ## 3 Afghanistan ## 4 Afghanistan ## ... ## 1699 Zimbabwe ## 1700 Zimbabwe ## 1701 Zimbabwe ## 1702 Zimbabwe ## 1703 Zimbabwe ## Name: country, Length: 1704, dtype: object And then if we wanted to select all rows but only the second and third columns, we could do so like this:\n1 df.iloc[:, 1:3] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## continent year ## 0 Asia 1952 ## 1 Asia 1957 ## 2 Asia 1962 ## 3 Asia 1967 ## 4 Asia 1972 ## ... ... ... ## 1699 Africa 1987 ## 1700 Africa 1992 ## 1701 Africa 1997 ## 1702 Africa 2002 ## 1703 Africa 2007 ## ## [1704 rows x 2 columns] Logical Subsetting So far, we haven’t applied many conditions to our subsets, but we can. In logical subsetting, the subset defaults to returning the results where the condition is TRUE.\nRecall, Python allows us to specify several conditions:\nless than \u0026gt; greater than \u0026lt; less than or equal to \u0026lt;= greater than or equal \u0026gt;= equivalent to == not equivalent to != As well as boolean operators\nor | and \u0026amp; 1 2 df_3 = df[df[\u0026#39;pop\u0026#39;] \u0026gt; 10000000] # all variables for when population is greater than 10 million df_3.head() 1 2 3 4 5 6 ## country continent year lifeExp pop gdpPercap ## 2 Afghanistan Asia 1962 31.997 10267083 853.100710 ## 3 Afghanistan Asia 1967 34.020 11537966 836.197138 ## 4 Afghanistan Asia 1972 36.088 13079460 739.981106 ## 5 Afghanistan Asia 1977 38.438 14880372 786.113360 ## 6 Afghanistan Asia 1982 39.854 12881816 978.011439 If we wanted to filter by country name and year, without saving to a new data frame, we can do so like this:\n1 df[(df[\u0026#39;country\u0026#39;] == \u0026#39;Canada\u0026#39;) \u0026amp; (df[\u0026#39;year\u0026#39;] \u0026gt;= 2000)] 1 2 3 ## country continent year lifeExp pop gdpPercap ## 250 Canada Americas 2002 79.770 31902268 33328.96507 ## 251 Canada Americas 2007 80.653 33390141 36319.23501 Let’s say you want to know the average life expectancy in Australia for all recorded years before 2000. Try this as an exercise. To calculate this, we will first have to filter our data frame with two conditions, and then we will have to calculate the mean.\nHint: We can calculate the mean for all columns at once, and then just read off the Life Expectancy value to get the answer we are looking for.\nThere are multiple ways to solve this. See the solutions below:\n1 2 # Solution 1 df[(df[\u0026#39;country\u0026#39;] == \u0026#39;Australia\u0026#39;) \u0026amp; (df[\u0026#39;year\u0026#39;] \u0026lt; 2000)].mean(numeric_only = True) 1 2 3 4 5 ## year 1.974500e+03 ## lifeExp 7.343500e+01 ## pop 1.358108e+07 ## gdpPercap 1.746440e+04 ## dtype: float64 1 2 3 # Solution 2 filtered_df = df[(df[\u0026#39;country\u0026#39;] == \u0026#39;Australia\u0026#39;) \u0026amp; (df[\u0026#39;year\u0026#39;] \u0026lt; 2000)] filtered_df[\u0026#39;lifeExp\u0026#39;].mean() 1 ## np.float64(73.435) There are many different ways that will lead to the same answer! Try to think of another way to do it!\n","date":"2023-07-07T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/subsetting-in-python/","title":"Subsetting in Python"},{"content":"In previous categories we have looked at cleaning, summarizing, and subsetting data, with some minor calculations, but we haven’t yet looked at analyzing our data.\nPython is a very powerful tool for data analysis. Similarly to R, we can fit linear models and view graphs. First, we will look at some basic data analysis processes in Python.\nLet’s re-load in our Gapminder data:\n1 2 3 import pandas as pd url = \u0026#39;https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv\u0026#39; df = pd.read_csv(url) Let’s say we want to fit a linear model to see if there is a relationship between population and time. First, let’s do this with the entire dataset with all countries.\nNote that OLS stands for ordinary least squares.\n1 2 3 4 5 6 7 import statsmodels.api as sm # define our x and y variables for clarity y = df[\u0026#39;pop\u0026#39;] x = df[\u0026#39;year\u0026#39;] x = sm.add_constant(x) model = sm.OLS(y,x).fit() model.summary() OLS Regression Results Dep. Variable: pop R-squared: 0.007 Model: OLS Adj. R-squared: 0.006 Method: Least Squares F-statistic: 11.61 Date: Tue, 08 Apr 2025 Prob (F-statistic): 0.000672 Time: 09:54:10 Log-Likelihood: -33902. No. Observations: 1704 AIC: 6.781e+04 Df Residuals: 1702 BIC: 6.782e+04 Df Model: 1 Covariance Type: nonrobust coef std err t P\u003e|t| [0.025 0.975] const -9.722e+08 2.94e+08 -3.306 0.001 -1.55e+09 -3.95e+08 year 5.061e+05 1.49e+05 3.407 0.001 2.15e+05 7.97e+05 Omnibus: 2403.823 Durbin-Watson: 0.187 Prob(Omnibus): 0.000 Jarque-Bera (JB): 438354.240 Skew: 8.286 Prob(JB): 0.00 Kurtosis: 79.807 Cond. No. 2.27e+05 Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 2.27e+05. This might indicate that there arestrong multicollinearity or other numerical problems. Let’s try fitting another linear model, but using only data from Africa.\n1 2 df_AF = df[df[\u0026#39;continent\u0026#39;] == \u0026#39;Africa\u0026#39;] df_AF.head() ## country continent year lifeExp pop gdpPercap ## 24 Algeria Africa 1952 43.077 9279525 2449.008185 ## 25 Algeria Africa 1957 45.685 10270856 3013.976023 ## 26 Algeria Africa 1962 48.303 11000948 2550.816880 ## 27 Algeria Africa 1967 51.407 12760499 3246.991771 ## 28 Algeria Africa 1972 54.518 14760787 4182.663766 1 2 3 4 5 y = df_AF[\u0026#39;pop\u0026#39;] x = df_AF[\u0026#39;year\u0026#39;] x = sm.add_constant(x) model1 = sm.OLS(y,x).fit() model1.summary() OLS Regression Results Dep. Variable: pop R-squared: 0.074 Model: OLS Adj. R-squared: 0.072 Method: Least Squares F-statistic: 49.66 Date: Tue, 08 Apr 2025 Prob (F-statistic): 4.87e-12 Time: 09:54:10 Log-Likelihood: -11192. No. Observations: 624 AIC: 2.239e+04 Df Residuals: 622 BIC: 2.240e+04 Df Model: 1 Covariance Type: nonrobust coef std err t P\u003e|t| [0.025 0.975] const -4.728e+08 6.85e+07 -6.902 0.000 -6.07e+08 -3.38e+08 year 2.438e+05 3.46e+04 7.047 0.000 1.76e+05 3.12e+05 Omnibus: 477.344 Durbin-Watson: 0.284 Prob(Omnibus): 0.000 Jarque-Bera (JB): 7771.738 Skew: 3.336 Prob(JB): 0.00 Kurtosis: 18.950 Cond. No. 2.27e+05 Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 2.27e+05. This might indicate that there arestrong multicollinearity or other numerical problems. ","date":"2023-07-06T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/basic-model-fitting-in-python/","title":"Basic Model Fitting in Python"},{"content":"Recall the URL with the country data. Let\u0026rsquo;s use this to practice some preliminary cleaning techniques.\n1 2 3 import pandas as pd url = \u0026#39;https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv\u0026#39; df = pd.read_csv(url) If we wanted to check and see if there are any empty values in the data frame, we could do so like this:\n1 df.isnull().sum().sum() 1 ## np.int64(0) Above, we summed over all rows and columns to see if there were null values. if we wanted to check for null values in just one column, we could do so like this:\n1 df[\u0026#39;country\u0026#39;].isnull().sum() 1 ## np.int64(0) Renaming Columns If we wanted to look at changing the names of the columns in the data frame, whether it is because of formatting or lack of clarity in the existing titles, we can do so easily.\nLet’s say we wanted to change country to Country. In order for the changes to save, we have to update our stored variable by starting the code with df = ....\n1 2 df = df.rename({\u0026#39;country\u0026#39;: \u0026#39;Country\u0026#39;}, axis = 1) df.head() 1 2 3 4 5 6 ## Country continent year lifeExp pop gdpPercap ## 0 Afghanistan Asia 1952 28.801 8425333 779.445314 ## 1 Afghanistan Asia 1957 30.332 9240934 820.853030 ## 2 Afghanistan Asia 1962 31.997 10267083 853.100710 ## 3 Afghanistan Asia 1967 34.020 11537966 836.197138 ## 4 Afghanistan Asia 1972 36.088 13079460 739.981106 Now let’s say we want to change lifeExp to Life_Expectancy, pop to Population and gdpPercap to GDP_per_Cap.\n1 2 3 4 df = df.rename({\u0026#39;lifeExp\u0026#39;: \u0026#39;Life_Expectancy\u0026#39;, \u0026#39;pop\u0026#39;: \u0026#39;Population\u0026#39;, \u0026#39;gdpPercap\u0026#39;: \u0026#39;GDP_per_Cap\u0026#39;}, axis = 1) df.head() 1 2 3 4 5 6 ## Country continent year Life_Expectancy Population GDP_per_Cap ## 0 Afghanistan Asia 1952 28.801 8425333 779.445314 ## 1 Afghanistan Asia 1957 30.332 9240934 820.853030 ## 2 Afghanistan Asia 1962 31.997 10267083 853.100710 ## 3 Afghanistan Asia 1967 34.020 11537966 836.197138 ## 4 Afghanistan Asia 1972 36.088 13079460 739.981106 Now that our column titles are in order, we can determine the relevance of all of them. Let’s say our analysis doesn’t need the continent column, so we can get rid of it to simplify our data. To delete columns, we can do so like this:\n1 2 df = df.drop(columns = {\u0026#39;continent\u0026#39;}, axis = 1) df.head() 1 2 3 4 5 6 ## Country year Life_Expectancy Population GDP_per_Cap ## 0 Afghanistan 1952 28.801 8425333 779.445314 ## 1 Afghanistan 1957 30.332 9240934 820.853030 ## 2 Afghanistan 1962 31.997 10267083 853.100710 ## 3 Afghanistan 1967 34.020 11537966 836.197138 ## 4 Afghanistan 1972 36.088 13079460 739.981106 If we deleted the column by accident, you just have to go back and run the original line of code where we loaded the data set to start fresh and remove the changes.\nLet’s take a look at the data types in our data frame.\n1 df.dtypes 1 2 3 4 5 6 ## Country object ## year int64 ## Life_Expectancy float64 ## Population int64 ## GDP_per_Cap float64 ## dtype: object Let’s say we want to change Life_Expectancy from a float (decimal value) to an integer.\n1 2 df[\u0026#39;Life_Expectancy\u0026#39;] = df[\u0026#39;Life_Expectancy\u0026#39;].astype(int) df.dtypes 1 2 3 4 5 6 ## Country object ## year int64 ## Life_Expectancy int64 ## Population int64 ## GDP_per_Cap float64 ## dtype: object We could also convert multiple column types at once like this:\n1 2 3 df = df.astype({\u0026#34;Life_Expectancy\u0026#34;: float, \u0026#34;Population\u0026#34;: float}) df.dtypes 1 2 3 4 5 6 ## Country object ## year int64 ## Life_Expectancy float64 ## Population float64 ## GDP_per_Cap float64 ## dtype: object If we wanted to count the number of unique values in a column, we could do so like this:\n1 df.Country.unique().size 1 ## 142 ","date":"2023-06-20T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/cleaning-data-in-python/","title":"Cleaning Data in Python"},{"content":"Occasionally we need to derive variables form existing information. A good example of this is conversion between scales. If we wanted to change a measurement from metres to kilometres or weight in pounds to kilograms, we could do this simply by performing a basic operation on an entire column. In this situation, let’s start by multiplying two columns together to create a new column. Recall the GDP dataset from previous articles. Let’s say we want to know the total GDP for the country. This could be calculated by multiplying the population by the GDP_per_Cap.\nIf you are just starting here, let’s re-load in the original Gapminder data:\n1 2 3 import pandas as pd url = \u0026#39;https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv\u0026#39; df = pd.read_csv(url) 1 2 df[\u0026#39;Total_GDP\u0026#39;] = df[\u0026#39;pop\u0026#39;] * df[\u0026#39;gdpPercap\u0026#39;] df.head() 1 2 3 4 5 6 ## country continent year lifeExp pop gdpPercap Total_GDP ## 0 Afghanistan Asia 1952 28.801 8425333 779.445314 6.567086e+09 ## 1 Afghanistan Asia 1957 30.332 9240934 820.853030 7.585449e+09 ## 2 Afghanistan Asia 1962 31.997 10267083 853.100710 8.758856e+09 ## 3 Afghanistan Asia 1967 34.020 11537966 836.197138 9.648014e+09 ## 4 Afghanistan Asia 1972 36.088 13079460 739.981106 9.678553e+09 Since the number is too large to actually interpret, let’s divide it by 1 billion so that the unit of measure is in billions.\n1 2 3 df[\u0026#39;Total_GDP\u0026#39;] = df[\u0026#39;Total_GDP\u0026#39;] / 1000000000 df = df.rename({\u0026#39;Total_GDP\u0026#39;: \u0026#39;TotalGDP_Bil\u0026#39;}, axis = 1) df.head() 1 2 3 4 5 6 ## country continent year lifeExp pop gdpPercap TotalGDP_Bil ## 0 Afghanistan Asia 1952 28.801 8425333 779.445314 6.567086 ## 1 Afghanistan Asia 1957 30.332 9240934 820.853030 7.585449 ## 2 Afghanistan Asia 1962 31.997 10267083 853.100710 8.758856 ## 3 Afghanistan Asia 1967 34.020 11537966 836.197138 9.648014 ## 4 Afghanistan Asia 1972 36.088 13079460 739.981106 9.678553 Note that if you were to run this multiple times, it would keep dividing by 1 billion each time, so we want to ensure it is only run once.\nNow, let’s say we want to create a new column that contains both the country and continent information together. This is a useful tool if you had information where a first name and last name were separated, or even there was a username and you wanted to create a new column by combining the username and an email extension. Let’s take a look at our example.\n1 2 df[\u0026#39;Country_Cont\u0026#39;] = df[\u0026#39;country\u0026#39;].astype(str) + \u0026#39;_\u0026#39; + df[\u0026#39;continent\u0026#39;] df.head() 1 2 3 4 5 6 7 8 ## country continent year ... gdpPercap TotalGDP_Bil Country_Cont ## 0 Afghanistan Asia 1952 ... 779.445314 6.567086 Afghanistan_Asia ## 1 Afghanistan Asia 1957 ... 820.853030 7.585449 Afghanistan_Asia ## 2 Afghanistan Asia 1962 ... 853.100710 8.758856 Afghanistan_Asia ## 3 Afghanistan Asia 1967 ... 836.197138 9.648014 Afghanistan_Asia ## 4 Afghanistan Asia 1972 ... 739.981106 9.678553 Afghanistan_Asia ## ## [5 rows x 8 columns] There are so many different ways to perform an operation like this. You could use the apply() function, the .agg() function, .map() function, and more!\nAs an exercise, try creating your own column using either a basic mathematical operation on an existing column, or by combining two columns, or anything else you can think of!\nSome examples:\nCreate a new column with the first three letters of the country name Convert the total GDP column back to the GDP per cap column by multiplying by 1 billion and then dividing by the population. Combine the country name with the year. Here are the solutions to the examples provided above.\n1 2 3 # Solution to #1 df[\u0026#39;first_3_letters\u0026#39;] = df.country.str[:3] df.head() 1 2 3 4 5 6 7 8 ## country continent year ... TotalGDP_Bil Country_Cont first_3_letters ## 0 Afghanistan Asia 1952 ... 6.567086 Afghanistan_Asia Afg ## 1 Afghanistan Asia 1957 ... 7.585449 Afghanistan_Asia Afg ## 2 Afghanistan Asia 1962 ... 8.758856 Afghanistan_Asia Afg ## 3 Afghanistan Asia 1967 ... 9.648014 Afghanistan_Asia Afg ## 4 Afghanistan Asia 1972 ... 9.678553 Afghanistan_Asia Afg ## ## [5 rows x 9 columns] 1 2 3 4 # Solution to #2 df[\u0026#39;converted_gdp_per_cap\u0026#39;] = df[\u0026#39;TotalGDP_Bil\u0026#39;] * 1000000000 df[\u0026#39;converted_gdp_per_cap\u0026#39;] = df[\u0026#39;converted_gdp_per_cap\u0026#39;] / df[\u0026#39;pop\u0026#39;] df.head() 1 2 3 4 5 6 7 8 ## country continent ... first_3_letters converted_gdp_per_cap ## 0 Afghanistan Asia ... Afg 779.445314 ## 1 Afghanistan Asia ... Afg 820.853030 ## 2 Afghanistan Asia ... Afg 853.100710 ## 3 Afghanistan Asia ... Afg 836.197138 ## 4 Afghanistan Asia ... Afg 739.981106 ## ## [5 rows x 10 columns] 1 2 3 # Solution to #3 df[\u0026#39;Country_Year\u0026#39;] = df[\u0026#39;country\u0026#39;].astype(str) + \u0026#39;_\u0026#39; + df[\u0026#39;year\u0026#39;].astype(str) df.head() 1 2 3 4 5 6 7 8 ## country continent ... converted_gdp_per_cap Country_Year ## 0 Afghanistan Asia ... 779.445314 Afghanistan_1952 ## 1 Afghanistan Asia ... 820.853030 Afghanistan_1957 ## 2 Afghanistan Asia ... 853.100710 Afghanistan_1962 ## 3 Afghanistan Asia ... 836.197138 Afghanistan_1967 ## 4 Afghanistan Asia ... 739.981106 Afghanistan_1972 ## ## [5 rows x 11 columns] ","date":"2023-06-20T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/creating-variables-in-python/","title":"Creating Variables in Python"},{"content":"You can use base Python to perform basic visualizations with a dataset. Let\u0026rsquo;s take a look at a few examples.\nLet’s re-load in our Gapminder data:\n1 2 3 import pandas as pd url = \u0026#39;https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv\u0026#39; df = pd.read_csv(url) 1 2 import matplotlib.pyplot as plt plt.scatter(x = df[\u0026#39;year\u0026#39;], y = df[\u0026#39;pop\u0026#39;]) 1 2 df_AF = df[df[\u0026#39;continent\u0026#39;] == \u0026#39;Africa\u0026#39;] df_AF.head() 1 2 3 4 5 6 ## country continent year lifeExp pop gdpPercap ## 24 Algeria Africa 1952 43.077 9279525 2449.008185 ## 25 Algeria Africa 1957 45.685 10270856 3013.976023 ## 26 Algeria Africa 1962 48.303 11000948 2550.816880 ## 27 Algeria Africa 1967 51.407 12760499 3246.991771 ## 28 Algeria Africa 1972 54.518 14760787 4182.663766 1 plt.scatter(x = df_AF[\u0026#39;year\u0026#39;], y = df_AF[\u0026#39;pop\u0026#39;]) Base Python works well for simple visualizations, but Altair is a package that helps to create personalized and detailed visualizations to suit any task. See the article titled \u0026lsquo;Visualizing with Altair in Python\u0026rsquo; to learn more about it.\n","date":"2023-06-15T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/basic-visualizations-in-python/","title":"Basic Visualizations in Python"},{"content":"Functions take in data and do things with that data. We can write our own functions, but generally in Python we’ll be using functions that have already been written or built.\nSimple functions can be in base Python or in different packages. Take these base Python functions for example:\n1 sum((1,1)) 1 ## 2 1 max([1, 2, 5, 8, 3]) 1 ## 8 Calling a function requires 2 things: the function itself and any arguments the function allows us to specify – one of these arguments is the data source, but there are usually other parameters we can specify.\nIf we want to understand how the built-in functions work, let’s define our own function for addition. We start by naming it, and then defining the arguments. Here, let\u0026rsquo;s call it \u0026lsquo;add\u0026rsquo; and it will take in two numbers, so we set the arbitrary names of these arguments to x and y.\n1 2 3 4 5 def add(x,y): answer = x + y return answer add(1,1) 1 ## 2 This is cool, but unnecessary work. It’s much easier to use the built-in function that we use above. This is why packages are so useful. Other people have spent time defining functions to do typical tasks, so we can use the existing work rather than duplicating effort.\nNote that there may be limitations or unexpected behaviours to a function. What would happen if we added x+y in this function?\n1 add(\u0026#39;x\u0026#39;,\u0026#39;y\u0026#39;) 1 ## \u0026#39;xy\u0026#39; This is something to consider when creating functions! It may not always be used for its intended use.\nIf we wanted to create a function to reverse a number, we could do that first by defining the name of our function, as well as how many arguments it requires. At the end, a function will need to do something either by using the command return or print or something else, otherwise it serves no purpose.\nWith this function, if we input the number 12345, we would expect it to return 54321.\n1 2 3 4 5 6 7 8 9 10 def reverse_num(number): num = number reversed_num = 0 while num != 0: digit = num % 10 reversed_num = reversed_num * 10 + digit num //= 10 print(\u0026#34;Reversed Number: \u0026#34; + str(reversed_num)) reverse_num(12345) 1 ## Reversed Number: 54321 It works! Can you think of any limitations or unexpected uses for this function?\n","date":"2023-06-15T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/defining-functions-in-python/","title":"Defining Functions in Python"},{"content":"A dictionary lists key-value pairs, which could also be thought of as associated values where a key matches to the associated value. Let\u0026rsquo;s look at a few examples.\n1 2 3 # Dictionary - mapping between values house = {\u0026#39;bedrooms\u0026#39;: 3, \u0026#39;bathrooms\u0026#39;: 2, \u0026#39;city\u0026#39;: \u0026#39;Kelowna\u0026#39;, \u0026#39;price\u0026#39;: 250000} 1 house[\u0026#39;price\u0026#39;] 1 ## 250000 1 2 course = {\u0026#39;Data Science\u0026#39;: [\u0026#39;DATA100\u0026#39;, \u0026#39;DATA200\u0026#39;, \u0026#39;DATA300\u0026#39;], \u0026#39;Science\u0026#39;: [\u0026#39;SCIENCE100\u0026#39;, \u0026#39;SCIENCE200\u0026#39;, \u0026#39;SCIENCE300\u0026#39;]} 1 course[\u0026#39;Data Science\u0026#39;] 1 ## [\u0026#39;DATA100\u0026#39;, \u0026#39;DATA200\u0026#39;, \u0026#39;DATA300\u0026#39;] What if we wanted to turn the following information into a dictionary.\nName ID Campus Courses Dan 12345678 Okanagan DATA100, ENGL100, HIST100, CHEM100 This is how we would do this:\n1 2 3 4 5 student = {\u0026#39;Name\u0026#39; : \u0026#39;Dan\u0026#39;, \u0026#39;ID\u0026#39; : 12345678, \u0026#39;Campus\u0026#39; : \u0026#39;Okanagan\u0026#39;, \u0026#39;Courses\u0026#39;: [\u0026#39;DATA100\u0026#39;, \u0026#39;ENGL100\u0026#39;, \u0026#39;HIST100\u0026#39;, \u0026#39;CHEM100\u0026#39;]} student 1 ## {\u0026#39;Name\u0026#39;: \u0026#39;Dan\u0026#39;, \u0026#39;ID\u0026#39;: 12345678, \u0026#39;Campus\u0026#39;: \u0026#39;Okanagan\u0026#39;, \u0026#39;Courses\u0026#39;: [\u0026#39;DATA100\u0026#39;, \u0026#39;ENGL100\u0026#39;, \u0026#39;HIST100\u0026#39;, \u0026#39;CHEM100\u0026#39;]} ","date":"2023-06-15T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/dictionaries-in-python/","title":"Dictionaries in Python"},{"content":"Lists are an important tool used in Python. Lists can contain elements of mixed types as well. Let\u0026rsquo;s look at a few examples.\n1 2 3 # List list1 = [] list1 1 ## [] 1 2 list2 = [1, \u0026#39;UBC\u0026#39;, 100] list2 1 ## [1, \u0026#39;UBC\u0026#39;, 100] Now let\u0026rsquo;s see a few operations we can perform on a list.\n1 len(list1) 1 ## 0 1 len(list2) 1 ## 3 1 2 # Indexing Example - we will talk more about this later on list2[2] 1 ## 100 Note - Python indexing starts at zero, so the first element in the list is 0, the second is 1, and the third is 2, so if we actually wanted the second element, we would have to do this:\n1 list2[1] 1 ## \u0026#39;UBC\u0026#39; 1 type(list2) 1 ## \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; 1 type(list2[1]) 1 ## \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; As we mentioned earlier, a main difference between lists and tuples is that lists are mutable. Mutable means that elements in a list can be appended, changed, or deleted.\n1 2 3 mixed_list = [1, \u0026#39;UBC\u0026#39;, 5.0, \u0026#39;1\u0026#39;] mixed_list.append(\u0026#39;New\u0026#39;) mixed_list 1 ## [1, \u0026#39;UBC\u0026#39;, 5.0, \u0026#39;1\u0026#39;, \u0026#39;New\u0026#39;] If we decided that we wanted to replace \u0026lsquo;New\u0026rsquo; with 4, we could do so like this:\n1 2 mixed_list[4]= 4 mixed_list 1 ## [1, \u0026#39;UBC\u0026#39;, 5.0, \u0026#39;1\u0026#39;, 4] If we wanted to remove elements from the list, we could do so like this:\n1 2 mixed_list.remove(\u0026#39;UBC\u0026#39;) mixed_list 1 ## [1, 5.0, \u0026#39;1\u0026#39;, 4] Note that this will only remove the first occurrence, if this happened to be in the list more than once. It would also call an error message if the element doesn\u0026rsquo;t exist.\nIf we wanted to remove it based on the index of the list:\n1 2 del mixed_list[0] mixed_list 1 ## [5.0, \u0026#39;1\u0026#39;, 4] ","date":"2023-06-15T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/lists-in-python/","title":"Lists in Python"},{"content":"Loops are a common tool used in Python to help users iterate through lists, or perform the same operation numerous times without added efforts.\nLet\u0026rsquo;s look at a few examples:\n1 2 3 4 5 # Loops for n in [0, 1, 5, 2, -5]: # this is inside the loop print(\u0026#34;The number is\u0026#34;, n, \u0026#34;and its squared value is\u0026#34;, n**2) 1 2 3 4 5 ## The number is 0 and its squared value is 0 ## The number is 1 and its squared value is 1 ## The number is 5 and its squared value is 25 ## The number is 2 and its squared value is 4 ## The number is -5 and its squared value is 25 1 # this is outside the loop 1 2 3 4 ## Loop s = \u0026#34;Python\u0026#34; for c in s: print(c + \u0026#34;!\u0026#34;) 1 2 3 4 5 6 ## P! ## y! ## t! ## h! ## o! ## n! 1 2 3 # range(10) sets values 0-9, because recall Python starts at 0, not 1 for i in range(10): print(i) 1 2 3 4 5 6 7 8 9 10 ## 0 ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 This is equivalent to writing:\n1 2 for i in range(0,10): print(i) 1 2 3 4 5 6 7 8 9 10 ## 0 ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 If we wanted it to start at 1 and go to 10 (inclusive), we would write:\n1 2 for i in range(1,11): print(i) 1 2 3 4 5 6 7 8 9 10 ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 ## 10 Other examples:\n1 2 3 #(start,end,increments) for i in range(0,101,10): print(i) 1 2 3 4 5 6 7 8 9 10 11 ## 0 ## 10 ## 20 ## 30 ## 40 ## 50 ## 60 ## 70 ## 80 ## 90 ## 100 1 2 3 4 n = 3 while n \u0026gt; 0: print(n) n = n - 1 1 2 3 ## 3 ## 2 ## 1 1 print(\u0026#34;Smile!\u0026#34;) 1 ## Smile! ","date":"2023-06-15T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/loops-in-python/","title":"Loops in Python"},{"content":"Since Python is so widely used, there are many people who contribute to continuously improving and developing it. Let’s imagine Python as a base version. It can do basic calculations, but it requires extra efforts to do more complicated things. People have created extras or add-ons to help create shortcuts for more complicated specific tasks or functions. These ‘add-ons’ are called modules. A module allows us to use already defined classes, functions, variables, and more. Packages are a collection of similar modules. These modules are stored together in a package to help with storage and ease of use.\nPackages can be imported to use to help make things easier. For example, there is a Python package called math that helps with basic mathematical operations.\nTo use a package or specific module within it, we use the import command. The format of these commands is as followed:\nimport package.subpackage.modulename\nWe can also nickname the packages to make it easier when we use them. This is done using the as statement. An example of this is import pandas as pd. By doing this, whenever a function from pandas is used, instead of having to type pandas.function_name, we can type pd.function_name. This may not seem like a big difference, but when it is used repeatedly, this can save a lot of time and effort.\nA few of the main packages used in python include:\nPackage Name Usage Standard Import Command NumPy Used for arrays, matricies and mathematical functions import numpy as np pandas Used with data frames import pandas as pd matplotlib Typically used for plotting functions from matplotlib import pyplot as plt altair More advanced plotting options import altair as alt SciPy Used for scientific and technical computing import scipy There are many other packages available, and you can even create your own as well! To see a list of the top packages available in Python, visit this link.\n","date":"2023-06-15T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/packages-in-python/","title":"Packages in Python"},{"content":"When we talk about data, we can talk about data types, data classes, and data structures.\nData types are fundamental building blocks for storing information. Below, we can see a chart of all of the datatypes in Python.\nEnglish name Type name Description Example integer int positive/negative whole numbers 13 floating point number float real number in decimal form 3.1415 boolean bool true or false True string str text \u0026ldquo;Do you like Python?\u0026quot; list list a collection of objects - mutable \u0026amp; ordered [\u0026lsquo;Hi\u0026rsquo;,\u0026lsquo;Hello\u0026rsquo;,\u0026lsquo;Hola\u0026rsquo;] tuple tuple a collection of objects - immutable \u0026amp; ordered (\u0026lsquo;Tuesday\u0026rsquo;,3,14,2023) dictionary dict mapping of key-value pairs {\u0026rsquo;name\u0026rsquo;:\u0026lsquo;Madison\u0026rsquo;,\u0026lsquo;Program\u0026rsquo;:\u0026lsquo;Data Science\u0026rsquo;,\u0026lsquo;Age\u0026rsquo;:23} none NoneType represents no value None Note that character data, also known as strings, are always wrapped in “quotation marks”. You can use single quotes like ‘this’ or double quotes like “this”. As long as you use two of the same, it doesn’t matter which you use!\nWe can use the function type() to view the datatype of the stored value in a variable. Let’s explore a few examples of this.\n1 2 3 # Datatype x = 1 + 1 type(x) 1 ## \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; 1 2 x = 2.0 type(x) 1 ## \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; 1 2 3 # String string = \u0026#39;Okanagan\u0026#39; print(string) 1 ## Okanagan 1 type(x) 1 ## \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; Comparison Operators We can compare objects (or variables) using comparison operators. The result is a Boolean value. Recall from above that a Boolean gives either a True or False.\nFirst, let\u0026rsquo;s look at a table of the different comparison operators.\nComparison Operators Operator Description x == y is x equal to y? x != y is x not equal to y? x \u0026gt; y is x greater than y? x \u0026gt;= y is x greater than or equal to y? x \u0026lt; y is x less than y? x \u0026lt;= y is x less than or equal to y? x is y is x the same object as y? x and y are x and y both true? x or y is at least one of x and y true? not x is x false? Now, let\u0026rsquo;s look at a few examples.\n1 5 \u0026lt; 7 1 ## True 1 2 3 five = 5 seven = 7 five \u0026lt; seven 1 ## True 1 5.0 == 5 1 ## True 1 5.0 == \u0026#39;5\u0026#39; 1 ## False Lists Lists are an important tool used in Python. Lists can contain elements of mixed types as well. Let\u0026rsquo;s look at a few examples.\n1 2 3 # List list1 = [] list1 1 ## [] 1 2 list2 = [1, \u0026#39;UBC\u0026#39;, 100] list2 1 ## [1, \u0026#39;UBC\u0026#39;, 100] Now let\u0026rsquo;s see a few operations we can perform on a list.\n1 len(list1) 1 ## 0 1 len(list2) 1 ## 3 1 2 # Indexing Example - we will talk more about this later on list2[2] 1 ## 100 Note - Python indexing starts at zero, so the first element in the list is 0, the second is 1, and the third is 2, so if we actually wanted the second element, we would have to do this:\n1 list2[1] 1 ## \u0026#39;UBC\u0026#39; 1 type(list2) 1 ## \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; 1 type(list2[1]) 1 ## \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; As we mentioned earlier, a main difference between lists and tuples is that lists are mutable. Mutable means that elements in a list can be appended, changed, or deleted.\n1 2 3 mixed_list = [1, \u0026#39;UBC\u0026#39;, 5.0, \u0026#39;1\u0026#39;] mixed_list.append(\u0026#39;New\u0026#39;) mixed_list 1 ## [1, \u0026#39;UBC\u0026#39;, 5.0, \u0026#39;1\u0026#39;, \u0026#39;New\u0026#39;] If we decided that we wanted to replace \u0026lsquo;New\u0026rsquo; with 4, we could do so like this:\n1 2 mixed_list[4]= 4 mixed_list 1 ## [1, \u0026#39;UBC\u0026#39;, 5.0, \u0026#39;1\u0026#39;, 4] If we wanted to remove elements from the list, we could do so like this:\n1 2 mixed_list.remove(\u0026#39;UBC\u0026#39;) mixed_list 1 ## [1, 5.0, \u0026#39;1\u0026#39;, 4] Note that this will only remove the first occurrence, if this happened to be in the list more than once. It would also call an error message if the element doesn\u0026rsquo;t exist.\nIf we wanted to remove it based on the index of the list:\n1 2 del mixed_list[0] mixed_list 1 ## [5.0, \u0026#39;1\u0026#39;, 4] Dictionaries A dictionary lists key-value pairs, which could also be thought of as associated values where a key matches to the associated value. Let\u0026rsquo;s look at a few examples.\n1 2 3 # Dictionary - mapping between values house = {\u0026#39;bedrooms\u0026#39;: 3, \u0026#39;bathrooms\u0026#39;: 2, \u0026#39;city\u0026#39;: \u0026#39;Kelowna\u0026#39;, \u0026#39;price\u0026#39;: 250000} 1 house[\u0026#39;price\u0026#39;] 1 ## 250000 1 2 course = {\u0026#39;Data Science\u0026#39;: [\u0026#39;DATA100\u0026#39;, \u0026#39;DATA200\u0026#39;, \u0026#39;DATA300\u0026#39;], \u0026#39;Science\u0026#39;: [\u0026#39;SCIENCE100\u0026#39;, \u0026#39;SCIENCE200\u0026#39;, \u0026#39;SCIENCE300\u0026#39;]} 1 course[\u0026#39;Data Science\u0026#39;] 1 ## [\u0026#39;DATA100\u0026#39;, \u0026#39;DATA200\u0026#39;, \u0026#39;DATA300\u0026#39;] Loops Loops are a common tool used in Python to help users iterate through lists, or perform the same operation numerous times without added efforts.\nLet\u0026rsquo;s look at a few examples:\n1 2 3 4 5 # Loops for n in [0, 1, 5, 2, -5]: # this is inside the loop print(\u0026#34;The number is\u0026#34;, n, \u0026#34;and its squared value is\u0026#34;, n**2) 1 2 3 4 5 ## The number is 0 and its squared value is 0 ## The number is 1 and its squared value is 1 ## The number is 5 and its squared value is 25 ## The number is 2 and its squared value is 4 ## The number is -5 and its squared value is 25 1 # this is outside the loop 1 2 3 4 ## Loop s = \u0026#34;Python\u0026#34; for c in s: print(c + \u0026#34;!\u0026#34;) 1 2 3 4 5 6 ## P! ## y! ## t! ## h! ## o! ## n! 1 2 3 # range(10) sets values 0-9, because recall Python starts at 0, not 1 for i in range(10): print(i) 1 2 3 4 5 6 7 8 9 10 ## 0 ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 This is equivalent to writing:\n1 2 for i in range(0,10): print(i) 1 2 3 4 5 6 7 8 9 10 ## 0 ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 If we wanted it to start at 1 and go to 10 (inclusive), we would write:\n1 2 for i in range(1,11): print(i) 1 2 3 4 5 6 7 8 9 10 ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 ## 10 Other examples:\n1 2 3 #(start,end,increments) for i in range(0,101,10): print(i) 1 2 3 4 5 6 7 8 9 10 11 ## 0 ## 10 ## 20 ## 30 ## 40 ## 50 ## 60 ## 70 ## 80 ## 90 ## 100 1 2 3 4 n = 3 while n \u0026gt; 0: print(n) n = n - 1 1 2 3 ## 3 ## 2 ## 1 1 print(\u0026#34;Smile!\u0026#34;) 1 ## Smile! Data Frames A data frame essentially functions as a series of connected vectors or lists, where each vector or list is a column. In this sense a data frame is also a special kind of list.\nIn a data frame, all vectors need to be of the same length. And while each vector must hold the same data type, not all vectors need to be of the same data type. Data frames also allow us to apply column names.\nLet\u0026rsquo;s look at an example of creating a dataframe from two lists.\n1 2 3 4 5 6 7 8 letter_list = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;f\u0026#39;, \u0026#39;g\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;i\u0026#39;] number_list = [1, 2, 3, 4, 5, 6, 7, 8, 9] import pandas as pd df = pd.DataFrame( {\u0026#39;Letters\u0026#39;: letter_list, \u0026#39;Numbers\u0026#39;: number_list}) df 1 2 3 4 5 6 7 8 9 10 ## Letters Numbers ## 0 a 1 ## 1 b 2 ## 2 c 3 ## 3 d 4 ## 4 e 5 ## 5 f 6 ## 6 g 7 ## 7 h 8 ## 8 i 9 Alternatively, you could write a data frame directly like this:\n1 2 3 4 df1 = pd.DataFrame({\u0026#39;x\u0026#39; : [1., 2., 3., 4.], \u0026#39;y\u0026#39; : [4., 3., 2., 1.], \u0026#39;z\u0026#39; : [1, 2, 3, 4]}) df1 1 2 3 4 5 ## x y z ## 0 1.0 4.0 1 ## 1 2.0 3.0 2 ## 2 3.0 2.0 3 ## 3 4.0 1.0 4 Data frames are a VERY powerful data type in Python. We will spend most of our remaining time working with data frames because there is so much to learn about.\n","date":"2023-06-15T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/python-data-types/","title":"Python Data Types"},{"content":"The Pandas package is the go-to package in Python for data frames and data set analysis.\nLet\u0026rsquo;s load in a dataset from a URL and then explore the data. We can enter the URL to the data set and save it as a variable so that it is easily accessible. Since the data set is a .csv file, we can use the pandas function read_csv() to save the data into a data frame!\n1 2 3 import pandas as pd # we nickname it pd to save time when calling it later url = \u0026#39;https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv\u0026#39; df = pd.read_csv(url) We name the data set df which is short for data frame. This is just a common name used for naming data, but any name could be used depending on preference.\nThe head() function is often used to show the first few rows of a data frame. The default is the first five rows, but you can enter a different value inside the brackets to get the first n number of rows.\n1 df.head() 1 2 3 4 5 6 ## country continent year lifeExp pop gdpPercap ## 0 Afghanistan Asia 1952 28.801 8425333 779.445314 ## 1 Afghanistan Asia 1957 30.332 9240934 820.853030 ## 2 Afghanistan Asia 1962 31.997 10267083 853.100710 ## 3 Afghanistan Asia 1967 34.020 11537966 836.197138 ## 4 Afghanistan Asia 1972 36.088 13079460 739.981106 But if we only wanted to see the first 3 rows\u0026hellip;\n1 df.head(3) 1 2 3 4 ## country continent year lifeExp pop gdpPercap ## 0 Afghanistan Asia 1952 28.801 8425333 779.445314 ## 1 Afghanistan Asia 1957 30.332 9240934 820.853030 ## 2 Afghanistan Asia 1962 31.997 10267083 853.100710 Remember, Python starts at 0 and not 1, so the first row of data is technically zero! Also, notice that pandas noticed that the first row of the csv file was header names, so it automatically created column titles.\nWe can also do this for the last few rows of the data set, know as the tail.\n1 df.tail() 1 2 3 4 5 6 ## country continent year lifeExp pop gdpPercap ## 1699 Zimbabwe Africa 1987 62.351 9216418 706.157306 ## 1700 Zimbabwe Africa 1992 60.377 10704340 693.420786 ## 1701 Zimbabwe Africa 1997 46.809 11404948 792.449960 ## 1702 Zimbabwe Africa 2002 39.989 11926563 672.038623 ## 1703 Zimbabwe Africa 2007 43.487 12311143 469.709298 We can now explore the data a bit more, looking at the data types and data structures.\nWe can use the .info() function to get a summary of data frame information, such as the count of null values, data types, etc. Take a look below.\n1 df.info() 1 2 3 4 5 6 7 8 9 10 11 12 13 ## \u0026lt;class \u0026#39;pandas.core.frame.DataFrame\u0026#39;\u0026gt; ## RangeIndex: 1704 entries, 0 to 1703 ## Data columns (total 6 columns): ## # Column Non-Null Count Dtype ## --- ------ -------------- ----- ## 0 country 1704 non-null object ## 1 continent 1704 non-null object ## 2 year 1704 non-null int64 ## 3 lifeExp 1704 non-null float64 ## 4 pop 1704 non-null int64 ## 5 gdpPercap 1704 non-null float64 ## dtypes: float64(2), int64(2), object(2) ## memory usage: 80.0+ KB We can also quickly see summary statistics using the .describe() function.\n1 df.describe() 1 2 3 4 5 6 7 8 9 ## year lifeExp pop gdpPercap ## count 1704.00000 1704.000000 1.704000e+03 1704.000000 ## mean 1979.50000 59.474439 2.960121e+07 7215.327081 ## std 17.26533 12.917107 1.061579e+08 9857.454543 ## min 1952.00000 23.599000 6.001100e+04 241.165876 ## 25% 1965.75000 48.198000 2.793664e+06 1202.060309 ## 50% 1979.50000 60.712500 7.023596e+06 3531.846988 ## 75% 1993.25000 70.845500 1.958522e+07 9325.462346 ## max 2007.00000 82.603000 1.318683e+09 113523.132900 If we wanted to know the number of unique values of a specific column, we could use the value_counts() function.\n1 df.country.value_counts() 1 2 3 4 5 6 7 8 9 10 11 12 13 ## country ## Afghanistan 12 ## Pakistan 12 ## New Zealand 12 ## Nicaragua 12 ## Niger 12 ## .. ## Eritrea 12 ## Equatorial Guinea 12 ## El Salvador 12 ## Egypt 12 ## Zimbabwe 12 ## Name: count, Length: 142, dtype: int64 This shows that there are 12 occurrences of each unique country value.\nIf we wanted to know the number of countries recorded for each year, how would we find that information?\nWe can do so like this:\n1 df.year.value_counts() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## year ## 1952 142 ## 1957 142 ## 1962 142 ## 1967 142 ## 1972 142 ## 1977 142 ## 1982 142 ## 1987 142 ## 1992 142 ## 1997 142 ## 2002 142 ## 2007 142 ## Name: count, dtype: int64 If we wanted to find specific values, let’s say the maximum values, we could use the function .max().\n1 df.max() 1 2 3 4 5 6 7 ## country Zimbabwe ## continent Oceania ## year 2007 ## lifeExp 82.603 ## pop 1318683096 ## gdpPercap 113523.1329 ## dtype: object Other similar functions include .min(), .mean(), and .median().\nIf we wanted to group by specific data, let’s say country, and then apply an aggregate function, we could do it like this:\n1 df.groupby(\u0026#39;country\u0026#39;).max() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## continent year lifeExp pop gdpPercap ## country ## Afghanistan Asia 2007 43.828 31889923 978.011439 ## Albania Europe 2007 76.423 3600523 5937.029526 ## Algeria Africa 2007 72.301 33333216 6223.367465 ## Angola Africa 2007 42.731 12420476 5522.776375 ## Argentina Americas 2007 75.320 40301927 12779.379640 ## ... ... ... ... ... ... ## Vietnam Asia 2007 74.249 85262356 2441.576404 ## West Bank and Gaza Asia 2007 73.422 4018332 7110.667619 ## Yemen, Rep. Asia 2007 62.698 22211743 2280.769906 ## Zambia Africa 2007 51.821 11746035 1777.077318 ## Zimbabwe Africa 2007 62.351 12311143 799.362176 ## ## [142 rows x 5 columns] We can also group by multiple columns.\n1 df.groupby([\u0026#39;country\u0026#39;, \u0026#39;year\u0026#39;]).max() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## continent lifeExp pop gdpPercap ## country year ## Afghanistan 1952 Asia 28.801 8425333 779.445314 ## 1957 Asia 30.332 9240934 820.853030 ## 1962 Asia 31.997 10267083 853.100710 ## 1967 Asia 34.020 11537966 836.197138 ## 1972 Asia 36.088 13079460 739.981106 ## ... ... ... ... ... ## Zimbabwe 1987 Africa 62.351 9216418 706.157306 ## 1992 Africa 60.377 10704340 693.420786 ## 1997 Africa 46.809 11404948 792.449960 ## 2002 Africa 39.989 11926563 672.038623 ## 2007 Africa 43.487 12311143 469.709298 ## ## [1704 rows x 4 columns] If we wanted to know the number of countries in each continent recorded for each year, how would we find that information?\n1 df.groupby([\u0026#39;year\u0026#39;]).continent.value_counts() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 ## year continent ## 1952 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 1957 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 1962 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 1967 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 1972 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 1977 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 1982 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 1987 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 1992 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 1997 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 2002 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## 2007 Africa 52 ## Asia 33 ## Europe 30 ## Americas 25 ## Oceania 2 ## Name: count, dtype: int64 Notice that we did not change anything in our original data that we loaded in all of the code blocks above. We just simply viewed the data in different ways. If you wanted to clean the data or create a permanent copy of the grouped values, you would have to save it as a variable by typing a name on the left hand side, the equals sign, and then the action you want saved on the right hand side. For example:\n1 df2 = df.groupby([\u0026#39;year\u0026#39;]).continent.value_counts() Here we just did the same thing as earlier, but saved it to a new variable called df2.\n","date":"2023-06-15T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/viewing-data-in-python/","title":"Viewing Data in Python"},{"content":"R can be used as a generic calculator.\n1 1 + 1 1 ## [1] 2 1 2-3 1 ## [1] -1 1 6 / 2 1 ## [1] 3 1 3 * 4 1 ## [1] 12 Since R is so widely used, there are many people who contribute to continuously improving and developing it. Without anything added, R is a base version. It can do basic calculations, but it requires extra efforts to do more complicated things. People have created extras or add-ons to help create shortcuts for more complicated specific tasks or functions. These \u0026lsquo;add-ons\u0026rsquo; are called packages. Packages can be imported to use to help make things easier. For example, there is a large package in R called tidyverse that is very popular.\nFirst, packages must be installed, and then they have to be called. To install a package, use the command install.packages('package_name'). To call a package, use the command library(package_name). This is one example below:\n1 2 #install.packages(\u0026#39;matlib\u0026#39;) library(matlib) Once a package has been called, it does not need to be called again for the rest of this document. You can also import multiple packages within the same document. We will get into more useful packages later on!\nFor now, practice typing basic calculations into your R terminal to get used to the syntax, and see how easy it is to calculate things!\n","date":"2023-06-14T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/introduction-to-r/","title":"Introduction to R"},{"content":"Jupyter Notebook is a web-based interactive computing platform, and it can be used for many things, aside from Python. You can even use both R and Python within the same document.\nThink of Python (or R) as the language you are writing in, and Jupyter as the pen and pencil. This is how Python and Jupyter are used together.\nNote: There are many different IDEs (integrated development environment) for Python. To name a few, Programiz, Atom, Visual Studio Code, Spyder, and many more. If a Jupyter install is causing trouble, or if you do not like the interface and want something similar to R Studio, Spyder is a good option because it is a very familiar interface for R Studio users. Programiz is also great because it doesn\u0026rsquo;t require an install.\nSyzygy Syzygy (pronunciation up for debate) is a great way to use Jupyter without having to download it to your local computer. However, it does require your UBC login to use. It also can access your local files as well as UBC OneDrive files. To use, simply follow this link, click the sign on button in the top right, and use your UBC login to sign in. You will be able to creat files, view existing files, and enjoy all of the functionalities that Jupyter has to offer.\nDownloading Jupyter If you prefer to download Jupyter, it can be done with Anaconda. This video is a great resource explaining how to download both Jupyter and Anaconda, as well as how to get started using Jupyter.\nAlternatively, you can follow the instructions on this webpage to do the same install. Note that it has slightly different instructions for Windows and Mac users.\n","date":"2023-06-05T18:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/jupyter-notebook/","title":"Jupyter Notebook"},{"content":"CSV File Using the Pandas library, it is very easy to open a CSV file using Python. Simply import the package, and then use the line pd.read_csv(). See this example below:\n1 2 import pandas as pd df = pd.read_csv(\u0026#34;file.csv\u0026#34;) Note that this assumes the file you want to open follows the same filepath as your current directory. If you wanted to use a file in a different directory, simply use pd.read_csv(\u0026quot;/Users/name/rest_of_filepath/file.csv\u0026quot;) instead.\nAlternatively, if you were to use base Python, it gets a bit more complicated. Using the CSV library, it would have to be done by iterating through each row in the file. Printing each row would look like this:\n1 2 3 4 5 import csv with open(\u0026#34;file.csv\u0026#34;, \u0026#39;r\u0026#39;) as file: csvreader = csv.reader(file) for row in csvreader: print(row) 1 2 3 4 5 ## [\u0026#39;12\\t12\u0026#39;] ## [\u0026#39;34\\t1\u0026#39;] ## [\u0026#39;1\\t1\u0026#39;] ## [\u0026#39;1\\t1\u0026#39;] ## [\u0026#39;1\\t1\u0026#39;] Text File Similarly, for a text file, we can use Pandas to simplify the process. We can use the line pd.read_fwf() to read in a .txt file. For reference, FWF stands for fixed width lines which allows the lengths and features of the file to be specified as fixed values so that it can be read in to Python systematically. See this example below:\n1 2 import pandas as pd df = pd.read_fwf(\u0026#39;file.txt\u0026#39;) Alternatively, you can also iterate through each row similar to the csv format mentioned above, but we will not go through that. If you would like to try it as an exercise, simply use the second method above in the CSV section and change the file formatting to fit a .txt file.\nURL You can also access data on the internet without having to save a local copy. Take this website for example: Gapminder Data\nIf you follow the link, you will see that it is simply a CSV file with no other formatting or permissions to enter. If we wanted to read this into our Python script, we could do it like this:\n1 2 3 import pandas as pd url = \u0026#39;https://raw.githubusercontent.com/jstaf/gapminder/master/gapminder/gapminder.csv\u0026#39; df = pd.read_csv(url) There are many other file formats and ways to load files into Python. There are great resources online for any other file formats, but these examples above should get you started.\n","date":"2023-06-05T11:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/reading-data-in-python/","title":"Reading Data in Python"},{"content":" It is good practice to have descriptive but concise file names so one can easily find the code they are looking for. But as projects grow, the number of scripts can become quite large (unless you are one of those chaotic people that put everything in a single script\u0026hellip;). With UNIX computers, one can easily search for code in the a file explorer window, but this does not work with Windows. It is possible to search for files by name, but it is not possible to search for specific content in R scripts.\nThe findR package allows Windows users to search for specific strings of code within directories using a simple syntax:\n1 2 3 4 library(\u0026#39;findR\u0026#39;) findRscript(pattern = \u0026#39;a string of code\u0026#39;, path = \u0026#39;my-folder\u0026#39;, case.sensitive = TRUE) The pattern argument can be any code string, but note that single and double quotes need to be escaped by placing a \\ before them (i.e., \\' and \\\u0026quot;), while some special characters need to be preceeded by \\\\, such as +, (. Failing to escape and double-escape special characters will cause the function to miss the files or fail:\n1 findRscript(\u0026#39;library(\\\u0026#39;ctmm\\\u0026#39;)\u0026#39;, path = \u0026#39;H:/GitHub/env-var-review/analysis\u0026#39;) 1 ## No R scripts found! 1 findRscript(\u0026#39;library\\\\(\\\u0026#39;ctmm\\\u0026#39;\\\\)\u0026#39;, path = \u0026#39;H:/GitHub/env-var-review/analysis\u0026#39;) 1 ## No R scripts found! The package can also search for R Markdown files, PDFs, and text (.txt) files via the findRmd(), findPDF(), and findtxt() functions, respectively. Each of the functions can also copy the files that matched the pattern argument to a new folder (if copy = TRUE, but it is FALSE by default). You can decide which folder the files get copied to using the folder argument. Note that by default overwrite is set to TRUE, so any files present with the same name will be overwritten.\n","date":"2023-03-09T18:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/searching-for-files-with-the-findr-package/","title":"Searching for files with the `findR` package"},{"content":"\\usepackage{amsmath}\nThere are many different data structure types in R, each with varying levels of complexity and uses. The simplest data structure in R is a vector. Vectors are one-dimensional arrays (i.e., sets of values) of a single class (such as characters, numbers, dates, etc.), and they have a similar structure to the mathematical concept of vectors. For example, the vector $\\vec v$ with values 1, 4, 6, 2 would be:\n$$\\vec v = \\begin{bmatrix}1 \\\\ 4 \\\\ 6 \\\\ 2\\end{bmatrix}.$$In R we can create vectors using the c() function, as follows:\n1 2 v \u0026lt;- c(1, 4, 6, 2) v 1 ## [1] 1 4 6 2 (R prints vectors in a line rather than as columns to improve readability.)\nSince vectors can only contain elements of a common type, c() will force all elements to be of a single class. In the example below, I create a vector with the number 1, the letter \u0026ldquo;a\u0026rdquo;, today\u0026rsquo;s date, and the value TRUE (a boolean value), but c() coerces all values to be characters:\n1 c(1, \u0026#39;a\u0026#39;, Sys.Date(), TRUE) 1 ## [1] \u0026#34;1\u0026#34; \u0026#34;a\u0026#34; \u0026#34;20185\u0026#34; \u0026#34;TRUE\u0026#34; If we place two vectors (of the same class) side by side, we can create a matrix. Matrices are thus two-dimensional arrays\n1 2 # 2D arrays: matrices matrix(data = 1:8, nrow = 2) 1 2 3 ## [,1] [,2] [,3] [,4] ## [1,] 1 3 5 7 ## [2,] 2 4 6 8 1 matrix(data = 1:8, ncol = 2) 1 2 3 4 5 ## [,1] [,2] ## [1,] 1 5 ## [2,] 2 6 ## [3,] 3 7 ## [4,] 4 8 1 matrix(data = 1:8, ncol = 2, byrow = TRUE) 1 2 3 4 5 ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 ## [3,] 5 6 ## [4,] 7 8 1 2 # matrix operations matrix(1:9, ncol = 3) 1 2 3 4 ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 1 matrix(1:9, ncol = 3) + 3 1 2 3 4 ## [,1] [,2] [,3] ## [1,] 4 7 10 ## [2,] 5 8 11 ## [3,] 6 9 12 1 matrix(1:9, ncol = 3) * 2 # NOT matrix multiplication 1 2 3 4 ## [,1] [,2] [,3] ## [1,] 2 8 14 ## [2,] 4 10 16 ## [3,] 6 12 18 1 matrix(1:9, ncol = 3) %*% 6:8 # matrix multiplication 1 2 3 4 ## [,1] ## [1,] 90 ## [2,] 111 ## [3,] 132 1 matrix(1:9, ncol = 3) %*% matrix(1:6, ncol = 2) 1 2 3 4 ## [,1] [,2] ## [1,] 30 66 ## [2,] 36 81 ## [3,] 42 96 If we want to create an object that has different data types, a matrix or vector won\u0026rsquo;t work because R will force all items to be of the same type.\n1 class(c(0, 2)) 1 ## [1] \u0026#34;numeric\u0026#34; 1 class(c(0, 2, \u0026#39;a\u0026#39;)) # coerces all items to text 1 ## [1] \u0026#34;character\u0026#34; Instead, we need to use a list.\n1 2 3 4 5 # grouping objects with different and types: lists l \u0026lt;- list(letters = c(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;), numbers = 1:10, today = Sys.Date()) l 1 2 3 4 5 6 7 8 ## $letters ## [1] \u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34; ## ## $numbers ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## $today ## [1] \u0026#34;2025-04-07\u0026#34; 1 l$letters 1 ## [1] \u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34; 1 l$today 1 ## [1] \u0026#34;2025-04-07\u0026#34; If we want a list that has a table-like structure (which will likely be the case for a lot of the data you use in R), we can use a data frame.\n1 2 data.frame(num = 1:10, abc = LETTERS[1:10]) 1 2 3 4 5 6 7 8 9 10 11 ## num abc ## 1 1 A ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E ## 6 6 F ## 7 7 G ## 8 8 H ## 9 9 I ## 10 10 J 1 2 data.frame(num = 1:5, abc = LETTERS[1:10]) 1 2 3 4 5 6 7 8 9 10 11 ## num abc ## 1 1 A ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E ## 6 1 F ## 7 2 G ## 8 3 H ## 9 4 I ## 10 5 J 1 2 data.frame(num = 1:10, abc = LETTERS[1:9]) 1 ## Error in data.frame(num = 1:10, abc = LETTERS[1:9]): arguments imply differing number of rows: 10, 9 The tidyverse set of packages provides a \u0026ldquo;fancy data frame\u0026rdquo; that does not recycle elements (unless they are a single value), and allows you to reference other columns you previously created:\n1 2 3 library(\u0026#39;tibble\u0026#39;) tibble(num = 1:10, abc = LETTERS[num]) 1 2 3 4 5 6 7 8 9 10 11 12 13 ## # A tibble: 10 × 2 ## num abc ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 A ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E ## 6 6 F ## 7 7 G ## 8 8 H ## 9 9 I ## 10 10 J 1 2 tibble(num = 1:5, abc = LETTERS[1:10]) 1 2 3 4 5 ## Error in `tibble()`: ## ! Tibble columns must have compatible sizes. ## • Size 5: Existing data. ## • Size 10: Column `abc`. ## ℹ Only values of size one are recycled. ","date":"2023-03-07T11:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/data-structures-in-r/","title":"Data Structures in R"},{"content":"Python can be used as a calculator 1 1 + 1 1 ## 2 1 2-3 1 ## -1 1 6 / 2 1 ## 3.0 1 3 * 4 1 ## 12 Since Python is so widely used, there are many people who contribute to continuously improving and developing it. Let\u0026rsquo;s imagine Python as a base version. It can do basic calculations, but it requires extra efforts to do more complicated things. People have created extras or add-ons to help create shortcuts for more complicated specific tasks or functions. These \u0026lsquo;add-ons\u0026rsquo; are called packages. Packages can be imported to use to help make things easier. For example, there is a Python package called math that helps with basic mathematical operations. Let\u0026rsquo;s look at an example here of calling the package using the import command.\n1 2 import math math.sqrt(9) 1 ## 3.0 Once it has been imported, it does not need to be re-imported for the rest of this document. You can also import multiple packages within the same document. We will get into more useful packages later on!\n1 math.log(100) 1 ## 4.605170185988092 For now, practice typing basic calculations into your Python terminal to get used to the syntax, and see how easy it is to calculate things!\n","date":"2023-02-15T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/introduction-to-python/","title":"Introduction to Python"},{"content":" The default color palettes ggplot2 provides are generally good enough for a quick check, but they are overused and do not have very high contrast:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 library(\u0026#39;ggplot2\u0026#39;) # for fancy figures library(\u0026#39;khroma\u0026#39;) # for fancy palettes library(\u0026#39;cowplot\u0026#39;) # for fancy multi-panel figures library(\u0026#39;colorspace\u0026#39;) # required by colorblindr library(\u0026#39;colorblindr\u0026#39;) # to simulate colorblind vision theme_set(theme_bw()) # change default ggplot theme p \u0026lt;- ggplot(mtcars, aes(disp, mpg, color = factor(carb))) + geom_point() + labs(x = \u0026#39;Displacement (cubic inches)\u0026#39;, y = \u0026#39;Miles per gallon (US)\u0026#39;, color = \u0026#39;Carburetors\u0026#39;) p Additionally, they are not colorblind-friendly:\n1 cvd_grid(p) While ggplot2 offers additional color palettes with more contrast, many of them are still not colorblind-friendly:\n1 p + scale_color_brewer(type = \u0026#39;qual\u0026#39;, palette = 6) 1 cvd_grid(p + scale_color_brewer(type = \u0026#39;qual\u0026#39;, palette = 6)) And while the viridis palette (from the viridisLite package and included in the ggplot2 package) can be a good option for continuous palettes, it can still be hard to distinguish between colors in qualitative palettes:\n1 p + scale_color_viridis_d() 1 cvd_grid(p + scale_color_viridis_d()) The khroma package provides multiple high-contrast, colorblind-friendly palettes for qualitative, diverging and sequential data, based on the work of Paul Tol (https://personal.sron.nl/~pault/) and Fabio Crameri (https://www.fabiocrameri.ch/).\n1 p + khroma::scale_color_bright() 1 cvd_grid(p + scale_color_bright()) However, it is best to also use different shapes (in addition to different colors), when possible, to ensure people are able to distinguish between each legend item (which can be difficult with many colors \u0026ndash; compare colors for 3 and 8 for deutan and protan versions, as well as the desaturated version). We can do this by specifying the shape argument. Note that we also need to change the name of the shape legend to ensure we get a single legend:\n1 2 3 4 5 6 p_sh \u0026lt;- ggplot(mtcars, aes(disp, mpg, color = factor(carb))) + geom_point(aes(shape = factor(carb))) + labs(x = \u0026#39;Displacement (cubic inches)\u0026#39;, y = \u0026#39;Miles per gallon (US)\u0026#39;, color = \u0026#39;Carburetors\u0026#39;, shape = \u0026#39;Carburetors\u0026#39;) p_sh 1 cvd_grid(p_sh) Continuous vs discrete khroma color palettes Unlike with the ggplot functions for color palettes, the khroma function names do not specify whether the function will produce a continuous or discrete color palette. To avoid confusion, you can type khroma::scale_color_ and press Tab to see what functions the package offers, and a helpful window should show up beside the function suggestion:\n(If you want to change your RStudio theme, see this tutorial.)\nInstalling the necessary packages To install colorblindr, you will first need to install the cowplot and colorspace packages:\n1 2 3 4 remotes::install_github(\u0026#34;wilkelab/cowplot\u0026#34;) install.packages(\u0026#34;colorspace\u0026#34;, repos = \u0026#34;http://R-Forge.R-project.org\u0026#34;) remotes::install_github(\u0026#34;clauswilke/colorblindr\u0026#34;) install.packages(\u0026#39;khroma\u0026#39;) To read the help files for any of the functions in the packages, use the ? function, e.g. ?scale_color_bright.\n","date":"2023-02-11T10:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/making-colorblind-friendly-figures/","title":"Making Colorblind-Friendly Figures"},{"content":"Color schemes are a matter of preference, but I think many of us can agree that RStudio\u0026rsquo;s default theme is quite bright and low-contrast. Fortunately, RStudio offers some alternative themes, which you can see by clicking on Tools \u0026gt; Global Options in the top ribbon menu in RStudio. You can then select Appearance and change the Editor theme.\nOf the default themes, the Cobalt theme is my preferred one, but I find some of the colors to be too similar (such as the white for general text and the light blue used for headings in R Markdown documents). You can find the custom theme I use on my GitHub page. To add use this theme, go to Tools \u0026gt; Global Options, then select Appearance, and click on Add. Finally, select the Black Rmd.rstheme file, and click on Open.\n","date":"2023-02-11T09:00:00-08:00","permalink":"http://localhost:4321/csc-blog-new/p/changing-the-rstudio-theme/","title":"Changing the RStudio Theme"},{"content":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932 Including Plots You can also embed plots. See Figure 1 for example:\n1 2 3 4 5 6 7 par(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA ) Figure 1: A fancy pie chart.\n","date":"2020-12-01T21:13:14-05:00","permalink":"http://localhost:4321/csc-blog-new/p/hello-r-markdown/","title":"Hello R Markdown"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2019-03-09T00:00:00Z","image":"http://localhost:4321/csc-blog-new/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu_c1ca39d792aee4ab.jpg","permalink":"http://localhost:4321/csc-blog-new/p/placeholder-text/","title":"Placeholder Text"}]